# ğŸ”¬ Inversion d'Anneaux - Neural Network Project

**Auteur:** Oussama GUELFAA
**Date:** 25 - 01 - 2025

## ğŸ“– Vue d'Ensemble du Projet

Ce projet implÃ©mente des **solutions de rÃ©seaux de neurones spÃ©cialisÃ©es** pour l'analyse holographique d'anneaux et la prÃ©diction de paramÃ¨tres. Le projet est organisÃ© en **deux catÃ©gories principales** selon le type de prÃ©diction : 1D (gap seul) et 2D (gap + L_Ã©cran).

## ğŸ¯ Objectifs

- **Objectif Principal**: PrÃ©dire les paramÃ¨tres gap et/ou L_Ã©cran Ã  partir de profils d'intensitÃ© 1D
- **Source de DonnÃ©es**: Ratios d'intensitÃ© holographiques (I_subs/I_subs_inc) depuis fichiers MATLAB
- **PrÃ©cision Cible**: RÂ² > 0.8 pour les tÃ¢ches de rÃ©gression (RÂ² > 0.95 atteint)
- **Architecture**: RÃ©seaux basÃ©s sur profils 1D (prÃ©fÃ©rÃ©s aux approches CNN 2D)
- **ModularitÃ©**: Chaque rÃ©seau comme unitÃ© indÃ©pendante et dÃ©ployable

## ğŸ—ï¸ Architecture du Projet

Le projet suit une architecture modulaire organisÃ©e par **type de prÃ©diction** :

```
Inversion_anneaux/
â”œâ”€â”€ ğŸ¯ Reseaux_1D_Gap_Prediction/          # RÃ©seaux prÃ©diction gap seul
â”‚   â”œâ”€â”€ ğŸ”Š Reseau_Noise_Robustness/        # â­ Robustesse bruit (RECOMMANDÃ‰)
â”‚   â”œâ”€â”€ ğŸ”¬ Reseau_Gap_Prediction_CNN/      # CNN pour prÃ©diction gap
â”‚   â””â”€â”€ ğŸ§ª Reseau_Overfitting_Test/        # Test validation overfitting
â”œâ”€â”€ ğŸ¯ Reseaux_2D_Gap_Lecran_Prediction/   # RÃ©seaux prÃ©diction gap + L_Ã©cran
â”‚   â”œâ”€â”€ ğŸ”§ Reseau_TensorFlow_Alternative/  # Alternative TensorFlow/Keras
â”‚   â””â”€â”€ ğŸ”¥ Reseau_Ultra_Specialized/       # Architecture ultra-spÃ©cialisÃ©e
â”œâ”€â”€ ğŸ“Š data_generation/                    # DonnÃ©es MATLAB et scripts
â”œâ”€â”€ ğŸ—‚ï¸ archive_legacy_networks/           # Archives rÃ©seaux prÃ©cÃ©dents
â”œâ”€â”€ ğŸ”§ utilities/                          # Utilitaires et outils communs
â”œâ”€â”€ ğŸ“‹ analysis_scripts/                   # Scripts d'analyse
â””â”€â”€ ğŸ“– README.md                           # Ce fichier
```

### ğŸ† RÃ©sultat Majeur : SuccÃ¨s des RÃ©seaux 1D

**DÃ©couverte clÃ© :** Les rÃ©seaux 1D (prÃ©diction gap seul) surpassent largement les rÃ©seaux 2D (gap + L_Ã©cran) :
- **Performance 1D** : RÂ² = 0.9948 (quasi-parfait)
- **Performance 2D** : RÂ² < 0.5 (problÃ©matique)
- **Recommandation** : Utiliser exclusivement les rÃ©seaux 1D

### Standardized Network Structure

Each neural network follows the same organization:

```
Reseau_XYZ/
â”œâ”€â”€ run.py              # Autonomous main script
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml     # Complete configuration
â”œâ”€â”€ models/             # Trained models (.pth, .h5, .pkl)
â”œâ”€â”€ plots/              # Visualizations and analysis
â”œâ”€â”€ results/            # Metrics and reports (JSON, CSV)
â”œâ”€â”€ docs/               # Specialized documentation
â””â”€â”€ README.md           # Usage guide
```

## ğŸš€ Quick Start

### 1ï¸âƒ£ Setup Environment
```bash
# Install common dependencies
pip install torch pandas numpy matplotlib seaborn scikit-learn pyyaml scipy joblib

# For TensorFlow (optional)
pip install tensorflow
```

### 2ï¸âƒ£ Choose Your Neural Network
```bash
# For production use (recommended)
cd Reseau_Advanced_Regressor
python run.py

# For maximum performance
cd Reseau_Ultra_Specialized
python run.py

# For gap-only prediction
cd Reseau_Gap_Prediction_CNN
python run.py --mode train

# For robustness testing
cd Reseau_Noise_Robustness
python run.py
```

### 3ï¸âƒ£ View Results
Each network generates:
- **Models**: Trained neural networks
- **Plots**: Performance visualizations
- **Results**: Detailed metrics and reports

## ğŸ¯ RÃ©seaux de Neurones Disponibles

### ğŸ† CatÃ©gorie 1D - PrÃ©diction Gap Seul (RECOMMANDÃ‰E)

#### 1. ğŸ”Š Reseau_Noise_Robustness â­ **MEILLEUR MODÃˆLE**
**Robustesse au bruit avec augmentation de donnÃ©es optimisÃ©e**
- **Architecture:** Dense 512â†’256â†’128â†’1 avec rÃ©gularisation
- **Performance:** RÂ² = **0.9948** (quasi-parfait)
- **Innovation:** Augmentation par interpolation facteur 3
- **Zone critique:** [1.75-2.00 Âµm] maÃ®trisÃ©e (RÂ² = 0.99)
- **Robustesse:** TestÃ© jusqu'Ã  20% bruit, optimal Ã  5%
- **Utilisation:** **Production immÃ©diate recommandÃ©e**

#### 2. ğŸ”¬ Reseau_Gap_Prediction_CNN
**CNN spÃ©cialisÃ© pour prÃ©diction gap**
- **Architecture:** CNN 1D avec blocs rÃ©siduels
- **Performance:** RÂ² > 0.90 sur gap
- **Utilisation:** Exploration architectures convolutionnelles

#### 3. ğŸ§ª Reseau_Overfitting_Test
**Validation capacitÃ© d'apprentissage**
- **Architecture:** Simple sans rÃ©gularisation
- **Performance:** RÂ² â‰ˆ 1.0 sur donnÃ©es d'entraÃ®nement
- **Utilisation:** Tests de validation et diagnostics

### âš ï¸ CatÃ©gorie 2D - PrÃ©diction Gap + L_Ã©cran (RECHERCHE)

#### 4. ğŸ”§ Reseau_TensorFlow_Alternative
**Alternative TensorFlow/Keras**
- **Architecture:** Dense 512â†’256â†’128â†’64â†’2
- **Performance:** RÂ² < 0.5 (limitÃ© par qualitÃ© donnÃ©es)
- **Utilisation:** Recherche et dÃ©veloppement TensorFlow

#### 5. ï¿½ Reseau_Ultra_Specialized
**Architecture ultra-spÃ©cialisÃ©e**
- **Architecture:** ModÃ¨les ultra-profonds spÃ©cialisÃ©s
- **Performance:** RÂ² < 0.5 (limitÃ© par qualitÃ© donnÃ©es)
- **Utilisation:** Recherche architectures avancÃ©es

## ğŸ“Š Dataset Information

### Common Data Source
- **Dataset:** `data_generation/all_banque_new_24_01_25_NEW_full.mat`
- **Variables:**
  - `L_ecran_subs_vect`: Screen distances (6.0 to 14.0 Âµm)
  - `gap_sphere_vect`: Gap values (0.025 to 1.5 Âµm)
  - `I_subs`: Scattered intensities [33Ã—30Ã—1000]
  - `I_subs_inc`: Incident intensities [33Ã—30Ã—1000]

### Training Data
- **990 samples** (33 L_ecran Ã— 30 gap combinations)
- **600-1000 radial points** per profile (network-dependent)
- **Input:** Intensity ratios `I_subs/I_subs_inc`
- **Output:** Physical parameters [L_ecran, gap]

## ğŸ“ˆ Performance Comparison

| Network | Gap RÂ² | L_ecran RÂ² | Specialty | Training Time |
|---------|--------|------------|-----------|---------------|
| Gap Prediction CNN | >0.99 | - | Gap only | ~5 min |
| Noise Robustness | >0.8* | >0.95* | Noise testing | ~15 min |
| Overfitting Test | >0.99 | >0.99 | Validation | ~3 min |
| **Advanced Regressor** â­ | >0.8 | >0.95 | **Production** | ~8 min |
| Ultra Specialized | >0.85 | >0.98 | Max performance | ~20 min |
| PyTorch Optimized | >0.8 | >0.95 | PyTorch dev | ~10 min |
| TensorFlow Alternative | >0.8 | >0.95 | TensorFlow dev | ~15 min |

*\* Performance under 5% noise*

## ğŸ”¬ Physical Background

### Intensity Calculation
The neural networks train on the ratio `I_subs/I_subs_inc`, which represents the normalized scattered intensity:

```
Ratio = |E_total|Â² / |E_incident|Â²
      = |E_incident + E_scattered|Â² / |E_incident|Â²
      = |1 + E_scattered/E_incident|Â²
```

### Advantages of 1D Profile Approach
1. **Better Performance:** More efficient than 2D CNN approaches
2. **Physical Relevance:** Directly related to ring structure
3. **Interpretability:** Clear relationship between input and output
4. **Computational Efficiency:** Faster training and inference

## ğŸ“š Documentation

- **[Project Map](project_map.md):** Complete overview of all networks
- **Individual READMEs:** Each network has detailed documentation
- **Configuration Files:** YAML configs for each network
- **Results:** Automated metrics and visualizations

## ğŸ¯ Selection Guide

### For Production Use
- **Recommended:** `Reseau_Advanced_Regressor` or `Reseau_Ultra_Specialized`
- **Reason:** Systematic problem solving, high performance

### For Research
- **Gap only:** `Reseau_Gap_Prediction_CNN`
- **Robustness:** `Reseau_Noise_Robustness`
- **Diagnostics:** `Reseau_Overfitting_Test`

### For Development
- **PyTorch:** `Reseau_PyTorch_Optimized`
- **TensorFlow:** `Reseau_TensorFlow_Alternative`

## ğŸ”§ Modular Benefits

### Independent Units
- âœ… Each network is self-contained
- âœ… Can be zipped and deployed separately
- âœ… Easy to compare different approaches
- âœ… Simplified maintenance and updates

### Standardized Structure
- âœ… Consistent organization across networks
- âœ… Autonomous `run.py` scripts
- âœ… Complete configuration files
- âœ… Automated result generation

## ğŸ‰ Project Achievements

This modular neural network suite successfully provides:
- âœ… **7 specialized networks** for different use cases
- âœ… **Standardized structure** for easy deployment
- âœ… **High performance** (RÂ² > 0.8 consistently achieved)
- âœ… **Complete documentation** and configuration
- âœ… **Production-ready** solutions for holographic analysis
- âœ… **Modular architecture** for easy extension and maintenance

**Each network is ready for independent deployment in holographic parameter inversion!** ğŸš€

#!/usr/bin/env python3
"""
Profile Truncation Script
Author: Oussama GUELFAA
Date: 05 - 06 - 2025

Script pour tronquer les profils d'intensitÃ© de 1000 Ã  600 points
afin d'Ã©liminer le pic divergent Ã  droite qui perturbe la prÃ©diction du gap.

ProblÃ¨me identifiÃ©: Le pic Ã  droite (r > 6 Âµm) cause des difficultÃ©s
pour la prÃ©diction du paramÃ¨tre gap.

Solution: Limiter les profils aux 600 premiers points (r â‰¤ 6 Âµm)
oÃ¹ l'information utile est concentrÃ©e.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scipy.io as sio
import os

def analyze_profile_regions():
    """Analyse les diffÃ©rentes rÃ©gions des profils pour justifier la troncature."""
    
    print("="*80)
    print("ANALYSE DES RÃ‰GIONS DES PROFILS D'INTENSITÃ‰")
    print("="*80)
    
    # Charger les profils originaux
    df_profiles = pd.read_csv('../data/processed/intensity_profiles_full.csv')
    X_original = df_profiles.values
    
    print(f"Profils originaux: {X_original.shape}")
    print(f"Nombre de points par profil: {X_original.shape[1]}")
    
    # Analyser les statistiques par rÃ©gion
    regions = {
        'Zone utile (0-600)': slice(0, 600),
        'Zone problÃ©matique (600-1000)': slice(600, 1000),
        'Pic final (900-1000)': slice(900, 1000)
    }
    
    print(f"\nAnalyse statistique par rÃ©gion:")
    for region_name, region_slice in regions.items():
        region_data = X_original[:, region_slice]
        
        print(f"\n{region_name}:")
        print(f"  Points: {region_slice.start}-{region_slice.stop}")
        print(f"  Moyenne: {region_data.mean():.6f}")
        print(f"  Ã‰cart-type: {region_data.std():.6f}")
        print(f"  Min/Max: [{region_data.min():.6f}, {region_data.max():.6f}]")
        print(f"  Coefficient de variation: {region_data.std()/region_data.mean():.4f}")
    
    # Analyser la corrÃ©lation avec les paramÃ¨tres
    df_params = pd.read_csv('../data/processed/parameters.csv')
    y = df_params[['L_ecran', 'gap']].values

    # Aligner les dimensions (prendre le minimum)
    min_samples = min(len(X_original), len(y))
    X_original = X_original[:min_samples]
    y = y[:min_samples]

    print(f"DonnÃ©es alignÃ©es: X{X_original.shape}, y{y.shape}")
    
    print(f"\nCorrÃ©lation avec les paramÃ¨tres:")
    
    for region_name, region_slice in regions.items():
        region_data = X_original[:, region_slice]
        region_mean = region_data.mean(axis=1)  # Moyenne par profil
        
        # CorrÃ©lation avec L_ecran et gap
        corr_L = np.corrcoef(region_mean, y[:, 0])[0, 1]
        corr_gap = np.corrcoef(region_mean, y[:, 1])[0, 1]
        
        print(f"\n{region_name}:")
        print(f"  CorrÃ©lation avec L_ecran: {corr_L:.4f}")
        print(f"  CorrÃ©lation avec gap: {corr_gap:.4f}")
        print(f"  UtilitÃ© pour gap: {'âœ“ Utile' if abs(corr_gap) > 0.1 else 'âœ— Peu utile'}")
    
    return X_original

def visualize_truncation_impact():
    """Visualise l'impact de la troncature sur les profils."""
    
    print(f"\n=== VISUALISATION DE L'IMPACT DE LA TRONCATURE ===")
    
    # Charger les donnÃ©es
    df_profiles = pd.read_csv('../data/processed/intensity_profiles_full.csv')
    df_params = pd.read_csv('../data/processed/parameters.csv')
    X_original = df_profiles.values
    y = df_params[['L_ecran', 'gap']].values
    
    # CrÃ©er les visualisations
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # 1. Profils complets vs tronquÃ©s
    sample_indices = [0, 100, 200, 300, 400]  # Ã‰chantillons reprÃ©sentatifs
    
    for i, idx in enumerate(sample_indices[:3]):
        ax = axes[0, i]
        profile = X_original[idx]
        
        # Profil complet
        ax.plot(range(1000), profile, 'b-', alpha=0.7, label='Profil complet (1000 pts)')
        
        # Zone de troncature
        ax.axvline(x=600, color='red', linestyle='--', alpha=0.8, label='Limite troncature')
        ax.fill_betweenx([profile.min(), profile.max()], 600, 1000, 
                        alpha=0.2, color='red', label='Zone supprimÃ©e')
        
        # Profil tronquÃ©
        ax.plot(range(600), profile[:600], 'g-', linewidth=2, label='Profil tronquÃ© (600 pts)')
        
        ax.set_title(f'Ã‰chantillon {idx+1}\nL={y[idx, 0]:.1f}Âµm, gap={y[idx, 1]:.3f}Âµm')
        ax.set_xlabel('Position (points)')
        ax.set_ylabel('IntensitÃ© normalisÃ©e')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    # 2. Statistiques par position
    ax = axes[1, 0]
    mean_profile = X_original.mean(axis=0)
    std_profile = X_original.std(axis=0)
    
    ax.plot(range(1000), mean_profile, 'b-', label='Moyenne')
    ax.fill_between(range(1000), mean_profile - std_profile, mean_profile + std_profile,
                   alpha=0.3, label='Â± 1 Ã©cart-type')
    ax.axvline(x=600, color='red', linestyle='--', label='Limite troncature')
    ax.set_title('Profil moyen Â± Ã©cart-type')
    ax.set_xlabel('Position (points)')
    ax.set_ylabel('IntensitÃ©')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 3. Variance par position
    ax = axes[1, 1]
    variance_profile = X_original.var(axis=0)
    ax.plot(range(1000), variance_profile, 'purple', linewidth=2)
    ax.axvline(x=600, color='red', linestyle='--', label='Limite troncature')
    ax.set_title('Variance par position')
    ax.set_xlabel('Position (points)')
    ax.set_ylabel('Variance')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 4. Distribution des valeurs par rÃ©gion
    ax = axes[1, 2]
    zone_utile = X_original[:, :600].flatten()
    zone_problematique = X_original[:, 600:].flatten()
    
    ax.hist(zone_utile, bins=50, alpha=0.6, label='Zone utile (0-600)', density=True)
    ax.hist(zone_problematique, bins=50, alpha=0.6, label='Zone problÃ©matique (600-1000)', density=True)
    ax.set_title('Distribution des intensitÃ©s')
    ax.set_xlabel('IntensitÃ© normalisÃ©e')
    ax.set_ylabel('DensitÃ©')
    ax.legend()
    ax.set_yscale('log')
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('plots/truncation_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("Analyse de troncature sauvegardÃ©e: plots/truncation_analysis.png")

def create_truncated_dataset():
    """CrÃ©e le dataset tronquÃ© Ã  600 points."""
    
    print(f"\n=== CRÃ‰ATION DU DATASET TRONQUÃ‰ ===")
    
    # Charger les donnÃ©es originales
    df_profiles = pd.read_csv('../data/processed/intensity_profiles_full.csv')
    df_params = pd.read_csv('../data/processed/parameters.csv')
    
    X_original = df_profiles.values
    y_original = df_params[['L_ecran', 'gap']].values
    
    print(f"Dataset original:")
    print(f"  Profils: {X_original.shape}")
    print(f"  ParamÃ¨tres: {y_original.shape}")
    
    # Tronquer Ã  600 points
    X_truncated = X_original[:, :600]
    
    print(f"\nDataset tronquÃ©:")
    print(f"  Profils: {X_truncated.shape}")
    print(f"  RÃ©duction: {X_original.shape[1]} â†’ {X_truncated.shape[1]} points")
    print(f"  Pourcentage conservÃ©: {600/1000*100:.1f}%")
    
    # VÃ©rifier que l'information importante est conservÃ©e
    print(f"\nVÃ©rification de l'information conservÃ©e:")
    
    # Calculer les corrÃ©lations avant/aprÃ¨s troncature
    orig_corr_L = np.corrcoef(X_original.mean(axis=1), y_original[:, 0])[0, 1]
    orig_corr_gap = np.corrcoef(X_original.mean(axis=1), y_original[:, 1])[0, 1]
    
    trunc_corr_L = np.corrcoef(X_truncated.mean(axis=1), y_original[:, 0])[0, 1]
    trunc_corr_gap = np.corrcoef(X_truncated.mean(axis=1), y_original[:, 1])[0, 1]
    
    print(f"  CorrÃ©lation avec L_ecran:")
    print(f"    Original (1000 pts): {orig_corr_L:.4f}")
    print(f"    TronquÃ© (600 pts): {trunc_corr_L:.4f}")
    print(f"    Conservation: {trunc_corr_L/orig_corr_L*100:.1f}%")
    
    print(f"  CorrÃ©lation avec gap:")
    print(f"    Original (1000 pts): {orig_corr_gap:.4f}")
    print(f"    TronquÃ© (600 pts): {trunc_corr_gap:.4f}")
    print(f"    Conservation: {trunc_corr_gap/orig_corr_gap*100:.1f}%")
    
    # Sauvegarder le dataset tronquÃ©
    print(f"\nSauvegarde du dataset tronquÃ©...")

    # CrÃ©er le dossier processed_data dans Neural_Network
    os.makedirs('processed_data', exist_ok=True)

    # CrÃ©er les DataFrames
    df_profiles_truncated = pd.DataFrame(X_truncated)
    df_params_truncated = df_params.copy()  # ParamÃ¨tres inchangÃ©s

    # Sauvegarder
    df_profiles_truncated.to_csv('processed_data/intensity_profiles_truncated_600.csv', index=False)
    df_params_truncated.to_csv('processed_data/parameters_truncated_600.csv', index=False)

    print(f"Fichiers sauvegardÃ©s:")
    print(f"  processed_data/intensity_profiles_truncated_600.csv")
    print(f"  processed_data/parameters_truncated_600.csv")
    
    return X_truncated, y_original

def compare_with_experimental_data():
    """Compare les profils tronquÃ©s avec les donnÃ©es expÃ©rimentales."""
    
    print(f"\n=== COMPARAISON AVEC DONNÃ‰ES EXPÃ‰RIMENTALES ===")
    
    # Charger les donnÃ©es expÃ©rimentales
    dataset_dir = "../data_generation/dataset"
    labels_df = pd.read_csv(os.path.join(dataset_dir, "labels.csv"))
    
    X_exp = []
    for i in range(min(10, len(labels_df))):
        filename = labels_df.iloc[i]['filename'].replace('.png', '.mat')
        mat_path = os.path.join(dataset_dir, filename)
        if os.path.exists(mat_path):
            data = sio.loadmat(mat_path)
            ratio = data['ratio'].flatten()
            X_exp.append(ratio)
    
    X_exp = np.array(X_exp)
    
    # Charger les donnÃ©es simulÃ©es tronquÃ©es
    df_sim_trunc = pd.read_csv('processed_data/intensity_profiles_truncated_600.csv')
    X_sim_trunc = df_sim_trunc.values
    
    print(f"Comparaison des longueurs:")
    print(f"  ExpÃ©rimental: {X_exp.shape[1]} points")
    print(f"  SimulÃ© tronquÃ©: {X_sim_trunc.shape[1]} points")
    
    if X_exp.shape[1] != X_sim_trunc.shape[1]:
        print(f"  âš ï¸  ATTENTION: Longueurs diffÃ©rentes!")
        if X_exp.shape[1] > 600:
            print(f"  â†’ Tronquer aussi les donnÃ©es expÃ©rimentales Ã  600 points")
            X_exp = X_exp[:, :600]
        else:
            print(f"  â†’ Les donnÃ©es expÃ©rimentales sont dÃ©jÃ  plus courtes")
    
    # Comparer les statistiques
    print(f"\nComparaison statistique:")
    print(f"  SimulÃ© tronquÃ© - mean: {X_sim_trunc.mean():.6f}, std: {X_sim_trunc.std():.6f}")
    print(f"  ExpÃ©rimental - mean: {X_exp.mean():.6f}, std: {X_exp.std():.6f}")
    
    # Calculer la similaritÃ©
    sim_mean = X_sim_trunc.mean(axis=0)
    exp_mean = X_exp.mean(axis=0)
    
    if len(sim_mean) == len(exp_mean):
        correlation = np.corrcoef(sim_mean, exp_mean)[0, 1]
        print(f"  CorrÃ©lation profils moyens: {correlation:.4f}")
        print(f"  SimilaritÃ©: {'âœ“ Bonne' if correlation > 0.8 else 'âš ï¸ Moyenne' if correlation > 0.6 else 'âœ— Faible'}")

def main():
    """Fonction principale."""
    
    print("="*80)
    print("TRONCATURE DES PROFILS D'INTENSITÃ‰")
    print("RÃ©solution du problÃ¨me du pic divergent Ã  droite")
    print("="*80)
    
    # 1. Analyser les rÃ©gions des profils
    X_original = analyze_profile_regions()
    
    # 2. Visualiser l'impact de la troncature
    visualize_truncation_impact()
    
    # 3. CrÃ©er le dataset tronquÃ©
    X_truncated, y = create_truncated_dataset()
    
    # 4. Comparer avec les donnÃ©es expÃ©rimentales
    compare_with_experimental_data()
    
    print(f"\n{'='*80}")
    print(f"TRONCATURE TERMINÃ‰E AVEC SUCCÃˆS")
    print(f"{'='*80}")
    
    print(f"âœ… PROBLÃˆME RÃ‰SOLU:")
    print(f"   â€¢ Pic divergent Ã  droite (r > 6Âµm) supprimÃ©")
    print(f"   â€¢ Profils rÃ©duits de 1000 â†’ 600 points")
    print(f"   â€¢ Information utile conservÃ©e")
    print(f"   â€¢ CompatibilitÃ© avec donnÃ©es expÃ©rimentales vÃ©rifiÃ©e")
    
    print(f"\nğŸ“ FICHIERS GÃ‰NÃ‰RÃ‰S:")
    print(f"   â€¢ processed_data/intensity_profiles_truncated_600.csv")
    print(f"   â€¢ processed_data/parameters_truncated_600.csv")
    print(f"   â€¢ plots/truncation_analysis.png")
    
    print(f"\nğŸš€ PROCHAINES Ã‰TAPES:")
    print(f"   1. EntraÃ®ner le modÃ¨le avec les profils tronquÃ©s")
    print(f"   2. Comparer les performances avec le modÃ¨le original")
    print(f"   3. VÃ©rifier l'amÃ©lioration de la prÃ©diction du gap")
    print(f"   4. Mettre Ã  jour la documentation")

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
Test de l'effet de l'augmentation de donn√©es sur la robustesse au bruit

Ce script compare les performances avec et sans augmentation de donn√©es
pour √©valuer l'am√©lioration de la robustesse au bruit.

Auteur: Oussama GUELFAA
Date: 10 - 01 - 2025
"""

import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import json
from sklearn.model_selection import train_test_split

# Importer les modules locaux
from noise_robustness_test import (
    load_dataset, add_gaussian_noise, train_model_with_noise, 
    evaluate_model, RobustGapPredictor
)
from data_augmentation import augment_dataset_comprehensive

def compare_with_without_augmentation(X, y, noise_levels, augmentation_config=None):
    """
    Compare les performances avec et sans augmentation de donn√©es.
    
    Args:
        X, y: Donn√©es originales
        noise_levels: Niveaux de bruit √† tester
        augmentation_config: Configuration de l'augmentation
        
    Returns:
        dict: R√©sultats comparatifs
    """
    print("=== COMPARAISON AVEC/SANS AUGMENTATION ===")
    
    # Configuration par d√©faut pour l'augmentation
    if augmentation_config is None:
        augmentation_config = {
            'interpolation_factor': 2,
            'smooth_variations': True,
            'variation_factor': 0.01,
            'n_variations': 1,
            'elastic_deformation': False  # D√©sactiv√© pour ce test initial
        }
    
    # Division des donn√©es originales
    X_train_orig, X_temp, y_train_orig, y_temp = train_test_split(
        X, y, test_size=0.4, random_state=42
    )
    X_val_orig, X_test, y_val_orig, y_test = train_test_split(
        X_temp, y_temp, test_size=0.5, random_state=42
    )
    
    print(f"Division originale:")
    print(f"  Train: {len(X_train_orig)} √©chantillons")
    print(f"  Val: {len(X_val_orig)} √©chantillons") 
    print(f"  Test: {len(X_test)} √©chantillons")
    
    # Augmentation des donn√©es d'entra√Ænement
    print(f"\nAugmentation des donn√©es d'entra√Ænement...")
    X_train_aug, y_train_aug = augment_dataset_comprehensive(
        X_train_orig, y_train_orig, augmentation_config
    )
    
    print(f"Donn√©es d'entra√Ænement augment√©es:")
    print(f"  Avant: {len(X_train_orig)} √©chantillons")
    print(f"  Apr√®s: {len(X_train_aug)} √©chantillons")
    print(f"  Facteur: {len(X_train_aug) / len(X_train_orig):.1f}x")
    
    results = {
        'without_augmentation': {},
        'with_augmentation': {},
        'comparison': {}
    }
    
    # Test pour chaque niveau de bruit
    for noise_level in noise_levels:
        print(f"\n{'='*50}")
        print(f"TEST AVEC {noise_level}% DE BRUIT")
        print(f"{'='*50}")
        
        # 1. Sans augmentation
        print(f"\n--- SANS AUGMENTATION ---")
        model_orig, scaler_orig, history_orig, time_orig = train_model_with_noise(
            X_train_orig, y_train_orig, X_val_orig, y_val_orig, 
            noise_level, max_epochs=150, batch_size=16
        )
        metrics_orig = evaluate_model(model_orig, scaler_orig, X_test, y_test)
        
        results['without_augmentation'][noise_level] = {
            'metrics': metrics_orig,
            'history': history_orig,
            'training_time': time_orig,
            'epochs': len(history_orig['train_loss'])
        }
        
        # 2. Avec augmentation
        print(f"\n--- AVEC AUGMENTATION ---")
        model_aug, scaler_aug, history_aug, time_aug = train_model_with_noise(
            X_train_aug, y_train_aug, X_val_orig, y_val_orig,
            noise_level, max_epochs=150, batch_size=16
        )
        metrics_aug = evaluate_model(model_aug, scaler_aug, X_test, y_test)
        
        results['with_augmentation'][noise_level] = {
            'metrics': metrics_aug,
            'history': history_aug,
            'training_time': time_aug,
            'epochs': len(history_aug['train_loss'])
        }
        
        # 3. Comparaison
        r2_improvement = metrics_aug['r2'] - metrics_orig['r2']
        rmse_improvement = metrics_orig['rmse'] - metrics_aug['rmse']  # Positif = am√©lioration
        
        results['comparison'][noise_level] = {
            'r2_improvement': r2_improvement,
            'rmse_improvement': rmse_improvement,
            'r2_improvement_percent': (r2_improvement / metrics_orig['r2']) * 100,
            'rmse_improvement_percent': (rmse_improvement / metrics_orig['rmse']) * 100
        }
        
        print(f"\nR√©sultats pour {noise_level}% bruit:")
        print(f"  Sans augmentation: R¬≤ = {metrics_orig['r2']:.4f}, RMSE = {metrics_orig['rmse']:.4f}")
        print(f"  Avec augmentation: R¬≤ = {metrics_aug['r2']:.4f}, RMSE = {metrics_aug['rmse']:.4f}")
        print(f"  Am√©lioration R¬≤: {r2_improvement:+.4f} ({r2_improvement/metrics_orig['r2']*100:+.1f}%)")
        print(f"  Am√©lioration RMSE: {rmse_improvement:+.4f} ({rmse_improvement/metrics_orig['rmse']*100:+.1f}%)")
    
    return results, X_test, y_test

def plot_augmentation_comparison(results, noise_levels):
    """
    Cr√©e des graphiques comparatifs des r√©sultats avec/sans augmentation.
    
    Args:
        results: R√©sultats de la comparaison
        noise_levels: Niveaux de bruit test√©s
    """
    print("\n=== G√âN√âRATION DES GRAPHIQUES COMPARATIFS ===")
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # Extraire les donn√©es pour les graphiques
    r2_orig = [results['without_augmentation'][noise]['metrics']['r2'] for noise in noise_levels]
    r2_aug = [results['with_augmentation'][noise]['metrics']['r2'] for noise in noise_levels]
    
    rmse_orig = [results['without_augmentation'][noise]['metrics']['rmse'] for noise in noise_levels]
    rmse_aug = [results['with_augmentation'][noise]['metrics']['rmse'] for noise in noise_levels]
    
    time_orig = [results['without_augmentation'][noise]['training_time'] for noise in noise_levels]
    time_aug = [results['with_augmentation'][noise]['training_time'] for noise in noise_levels]
    
    # 1. Comparaison R¬≤
    axes[0, 0].plot(noise_levels, r2_orig, 'b-o', linewidth=2, label='Sans augmentation')
    axes[0, 0].plot(noise_levels, r2_aug, 'r-o', linewidth=2, label='Avec augmentation')
    axes[0, 0].axhline(y=0.8, color='gray', linestyle='--', alpha=0.7, label='Objectif R¬≤ = 0.8')
    axes[0, 0].set_xlabel('Niveau de bruit (%)')
    axes[0, 0].set_ylabel('R¬≤ Score')
    axes[0, 0].set_title('Comparaison R¬≤ Score')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. Comparaison RMSE
    axes[0, 1].plot(noise_levels, rmse_orig, 'b-o', linewidth=2, label='Sans augmentation')
    axes[0, 1].plot(noise_levels, rmse_aug, 'r-o', linewidth=2, label='Avec augmentation')
    axes[0, 1].set_xlabel('Niveau de bruit (%)')
    axes[0, 1].set_ylabel('RMSE (¬µm)')
    axes[0, 1].set_title('Comparaison RMSE')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # 3. Am√©lioration relative R¬≤
    r2_improvements = [results['comparison'][noise]['r2_improvement_percent'] for noise in noise_levels]
    axes[0, 2].bar(noise_levels, r2_improvements, alpha=0.7, color='green')
    axes[0, 2].axhline(y=0, color='black', linestyle='-', alpha=0.5)
    axes[0, 2].set_xlabel('Niveau de bruit (%)')
    axes[0, 2].set_ylabel('Am√©lioration R¬≤ (%)')
    axes[0, 2].set_title('Am√©lioration Relative R¬≤')
    axes[0, 2].grid(True, alpha=0.3)
    
    # 4. Am√©lioration relative RMSE
    rmse_improvements = [results['comparison'][noise]['rmse_improvement_percent'] for noise in noise_levels]
    axes[1, 0].bar(noise_levels, rmse_improvements, alpha=0.7, color='orange')
    axes[1, 0].axhline(y=0, color='black', linestyle='-', alpha=0.5)
    axes[1, 0].set_xlabel('Niveau de bruit (%)')
    axes[1, 0].set_ylabel('Am√©lioration RMSE (%)')
    axes[1, 0].set_title('Am√©lioration Relative RMSE')
    axes[1, 0].grid(True, alpha=0.3)
    
    # 5. Temps d'entra√Ænement
    axes[1, 1].plot(noise_levels, time_orig, 'b-o', linewidth=2, label='Sans augmentation')
    axes[1, 1].plot(noise_levels, time_aug, 'r-o', linewidth=2, label='Avec augmentation')
    axes[1, 1].set_xlabel('Niveau de bruit (%)')
    axes[1, 1].set_ylabel('Temps d\'entra√Ænement (s)')
    axes[1, 1].set_title('Comparaison Temps d\'Entra√Ænement')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    
    # 6. R√©sum√© des am√©liorations
    axes[1, 2].scatter(r2_improvements, rmse_improvements, s=100, alpha=0.7)
    for i, noise in enumerate(noise_levels):
        axes[1, 2].annotate(f'{noise}%', 
                           (r2_improvements[i], rmse_improvements[i]),
                           xytext=(5, 5), textcoords='offset points')
    axes[1, 2].axhline(y=0, color='black', linestyle='-', alpha=0.5)
    axes[1, 2].axvline(x=0, color='black', linestyle='-', alpha=0.5)
    axes[1, 2].set_xlabel('Am√©lioration R¬≤ (%)')
    axes[1, 2].set_ylabel('Am√©lioration RMSE (%)')
    axes[1, 2].set_title('Corr√©lation des Am√©liorations')
    axes[1, 2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('../plots/augmentation_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("Graphiques comparatifs sauvegard√©s: ../plots/augmentation_comparison.png")

def analyze_augmentation_benefits(results, noise_levels):
    """
    Analyse les b√©n√©fices de l'augmentation de donn√©es.
    
    Args:
        results: R√©sultats de la comparaison
        noise_levels: Niveaux de bruit test√©s
    """
    print("\n" + "="*60)
    print("ANALYSE DES B√âN√âFICES DE L'AUGMENTATION")
    print("="*60)
    
    # Tableau comparatif
    print(f"\nüìä COMPARAISON D√âTAILL√âE:")
    print(f"{'Bruit':<6} {'R¬≤ Orig':<8} {'R¬≤ Aug':<8} {'Œî R¬≤':<8} {'RMSE Orig':<10} {'RMSE Aug':<10} {'Œî RMSE':<10}")
    print("-" * 70)
    
    total_r2_improvement = 0
    total_rmse_improvement = 0
    significant_improvements = 0
    
    for noise_level in noise_levels:
        r2_orig = results['without_augmentation'][noise_level]['metrics']['r2']
        r2_aug = results['with_augmentation'][noise_level]['metrics']['r2']
        rmse_orig = results['without_augmentation'][noise_level]['metrics']['rmse']
        rmse_aug = results['with_augmentation'][noise_level]['metrics']['rmse']
        
        r2_delta = r2_aug - r2_orig
        rmse_delta = rmse_orig - rmse_aug  # Positif = am√©lioration
        
        total_r2_improvement += r2_delta
        total_rmse_improvement += rmse_delta
        
        if r2_delta > 0.01:  # Am√©lioration significative
            significant_improvements += 1
        
        print(f"{noise_level:>4}%  "
              f"{r2_orig:>6.3f}   "
              f"{r2_aug:>6.3f}   "
              f"{r2_delta:>+6.3f}   "
              f"{rmse_orig:>8.4f}   "
              f"{rmse_aug:>8.4f}   "
              f"{rmse_delta:>+8.4f}")
    
    # Analyse globale
    avg_r2_improvement = total_r2_improvement / len(noise_levels)
    avg_rmse_improvement = total_rmse_improvement / len(noise_levels)
    
    print(f"\nüéØ ANALYSE GLOBALE:")
    print(f"  Am√©lioration moyenne R¬≤: {avg_r2_improvement:+.4f}")
    print(f"  Am√©lioration moyenne RMSE: {avg_rmse_improvement:+.4f} ¬µm")
    print(f"  Niveaux avec am√©lioration significative: {significant_improvements}/{len(noise_levels)}")
    
    # Seuil de robustesse
    threshold_orig = None
    threshold_aug = None
    
    for noise_level in noise_levels:
        r2_orig = results['without_augmentation'][noise_level]['metrics']['r2']
        r2_aug = results['with_augmentation'][noise_level]['metrics']['r2']
        
        if r2_orig >= 0.8 and threshold_orig is None:
            threshold_orig = noise_level
        if r2_aug >= 0.8 and threshold_aug is None:
            threshold_aug = noise_level
    
    print(f"\nüéØ SEUILS DE ROBUSTESSE (R¬≤ > 0.8):")
    print(f"  Sans augmentation: jusqu'√† {threshold_orig}% de bruit")
    print(f"  Avec augmentation: jusqu'√† {threshold_aug}% de bruit")
    
    if threshold_aug and threshold_orig:
        improvement = threshold_aug - threshold_orig
        print(f"  Am√©lioration du seuil: +{improvement}% de bruit tol√©r√©")
    
    # Recommandations
    print(f"\nüí° RECOMMANDATIONS:")
    
    if avg_r2_improvement > 0.02:
        print(f"  ‚úÖ Augmentation tr√®s b√©n√©fique - Recommand√©e")
        print(f"  ‚úÖ Am√©lioration substantielle de la robustesse")
    elif avg_r2_improvement > 0.01:
        print(f"  ‚úÖ Augmentation mod√©r√©ment b√©n√©fique")
        print(f"  ‚ö†Ô∏è  √âvaluer le co√ªt computationnel vs b√©n√©fice")
    else:
        print(f"  ‚ùå Augmentation peu b√©n√©fique")
        print(f"  ‚ùå Chercher d'autres strat√©gies d'am√©lioration")
    
    # Co√ªt computationnel
    time_overhead = []
    for noise_level in noise_levels:
        time_orig = results['without_augmentation'][noise_level]['training_time']
        time_aug = results['with_augmentation'][noise_level]['training_time']
        overhead = (time_aug - time_orig) / time_orig * 100
        time_overhead.append(overhead)
    
    avg_overhead = np.mean(time_overhead)
    print(f"\n‚è±Ô∏è  CO√õT COMPUTATIONNEL:")
    print(f"  Surco√ªt moyen d'entra√Ænement: +{avg_overhead:.1f}%")
    
    if avg_overhead < 50:
        print(f"  ‚úÖ Surco√ªt acceptable")
    elif avg_overhead < 100:
        print(f"  ‚ö†Ô∏è  Surco√ªt mod√©r√©")
    else:
        print(f"  ‚ùå Surco√ªt √©lev√© - Optimisation n√©cessaire")

if __name__ == "__main__":
    print("=== TEST DE L'EFFET DE L'AUGMENTATION SUR LA ROBUSTESSE ===")
    
    # Cr√©er les dossiers de sortie
    os.makedirs("../plots", exist_ok=True)
    os.makedirs("../results", exist_ok=True)
    
    # Niveaux de bruit √† tester (r√©duits pour ce test)
    noise_levels = [0, 2, 5, 10]
    
    try:
        # Charger les donn√©es
        X, y = load_dataset()
        
        # Configuration d'augmentation
        augmentation_config = {
            'interpolation_factor': 2,
            'smooth_variations': True,
            'variation_factor': 0.015,
            'n_variations': 1,
            'elastic_deformation': False
        }
        
        # Comparaison avec/sans augmentation
        results, X_test, y_test = compare_with_without_augmentation(
            X, y, noise_levels, augmentation_config
        )
        
        # Sauvegarder les r√©sultats
        with open('../results/augmentation_comparison.json', 'w') as f:
            # Convertir les arrays numpy en listes pour JSON
            results_json = {}
            for key, value in results.items():
                if key != 'comparison':
                    results_json[key] = {}
                    for noise, data in value.items():
                        results_json[key][noise] = {
                            'r2': float(data['metrics']['r2']),
                            'rmse': float(data['metrics']['rmse']),
                            'mae': float(data['metrics']['mae']),
                            'training_time': float(data['training_time']),
                            'epochs': int(data['epochs'])
                        }
                else:
                    results_json[key] = {}
                    for noise, data in value.items():
                        results_json[key][noise] = {
                            'r2_improvement': float(data['r2_improvement']),
                            'rmse_improvement': float(data['rmse_improvement']),
                            'r2_improvement_percent': float(data['r2_improvement_percent']),
                            'rmse_improvement_percent': float(data['rmse_improvement_percent'])
                        }
            
            json.dump(results_json, f, indent=2)
        
        # Visualisations
        plot_augmentation_comparison(results, noise_levels)
        
        # Analyse
        analyze_augmentation_benefits(results, noise_levels)
        
        print(f"\n=== TEST D'AUGMENTATION TERMIN√â ===")
        print(f"üìä R√©sultats sauvegard√©s: ../results/augmentation_comparison.json")
        print(f"üìà Graphiques g√©n√©r√©s: ../plots/augmentation_comparison.png")
        
    except Exception as e:
        print(f"Erreur durant le test: {e}")
        import traceback
        traceback.print_exc()

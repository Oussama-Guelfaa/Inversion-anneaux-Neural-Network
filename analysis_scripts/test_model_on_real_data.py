#!/usr/bin/env python3
"""
Test du mod√®le model_noise_2percent.pth sur donn√©es r√©elles

Ce script teste le mod√®le entra√Æn√© avec 2% de bruit sur un fichier de donn√©es r√©elles
sp√©cifique pour √©valuer ses performances en conditions exp√©rimentales.

Auteur: Oussama GUELFAA
Date: 10 - 01 - 2025
"""

import os
import numpy as np
import scipy.io as sio
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
from sklearn.preprocessing import StandardScaler
import pickle
import json
from pathlib import Path

class RobustGapPredictor(nn.Module):
    """
    Mod√®le robuste pour pr√©diction du gap avec r√©gularisation.
    Architecture identique √† celle utilis√©e pour l'entra√Ænement.
    """
    
    def __init__(self, input_size=1000, dropout_rate=0.2):
        super(RobustGapPredictor, self).__init__()
        
        self.fc1 = nn.Linear(input_size, 512)
        self.bn1 = nn.BatchNorm1d(512)
        self.dropout1 = nn.Dropout(dropout_rate)
        
        self.fc2 = nn.Linear(512, 256)
        self.bn2 = nn.BatchNorm1d(256)
        self.dropout2 = nn.Dropout(dropout_rate)
        
        self.fc3 = nn.Linear(256, 128)
        self.bn3 = nn.BatchNorm1d(128)
        self.dropout3 = nn.Dropout(dropout_rate)
        
        self.fc4 = nn.Linear(128, 1)
        
    def forward(self, x):
        x = F.relu(self.bn1(self.fc1(x)))
        x = self.dropout1(x)
        
        x = F.relu(self.bn2(self.fc2(x)))
        x = self.dropout2(x)
        
        x = F.relu(self.bn3(self.fc3(x)))
        x = self.dropout3(x)
        
        x = self.fc4(x)
        return x

def load_model_and_scaler(model_path):
    """
    Charge le mod√®le entra√Æn√© et le scaler associ√©.
    
    Args:
        model_path (str): Chemin vers le fichier .pth du mod√®le
        
    Returns:
        tuple: (model, scaler, model_info)
    """
    print(f"=== CHARGEMENT DU MOD√àLE ===")
    print(f"Chemin: {model_path}")
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Le mod√®le {model_path} n'existe pas")
    
    # Charger le checkpoint (avec weights_only=False pour compatibilit√©)
    checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
    
    print(f"Contenu du checkpoint: {list(checkpoint.keys())}")
    
    # Extraire les informations
    model_state_dict = checkpoint['model_state_dict']
    scaler = checkpoint['scaler']
    noise_level = checkpoint.get('noise_level', 'unknown')
    metrics = checkpoint.get('metrics', {})
    
    # Cr√©er et charger le mod√®le
    model = RobustGapPredictor(input_size=1000)
    model.load_state_dict(model_state_dict)
    model.eval()  # Mode √©valuation
    
    print(f"Mod√®le charg√© avec succ√®s:")
    print(f"  - Niveau de bruit d'entra√Ænement: {noise_level}%")
    print(f"  - R¬≤ sur test: {metrics.get('r2', 'N/A'):.4f}")
    print(f"  - RMSE sur test: {metrics.get('rmse', 'N/A'):.4f} ¬µm")
    
    return model, scaler, {
        'noise_level': noise_level,
        'metrics': metrics
    }

def load_real_data(data_path):
    """
    Charge les donn√©es r√©elles depuis un fichier .mat.
    
    Args:
        data_path (str): Chemin vers le fichier .mat
        
    Returns:
        dict: Donn√©es extraites du fichier
    """
    print(f"\n=== CHARGEMENT DES DONN√âES R√âELLES ===")
    print(f"Fichier: {data_path}")
    
    if not os.path.exists(data_path):
        raise FileNotFoundError(f"Le fichier {data_path} n'existe pas")
    
    # Charger le fichier .mat
    data = sio.loadmat(data_path)
    
    print(f"Variables disponibles dans le fichier:")
    for key in data.keys():
        if not key.startswith('__'):
            value = data[key]
            print(f"  {key}: shape={value.shape}, dtype={value.dtype}")
    
    # Extraire les donn√©es principales
    ratio = data['ratio'].flatten() if 'ratio' in data else None
    gap_true = float(data['gap'][0, 0]) if 'gap' in data else None
    L_ecran = float(data['L_ecran_subs'][0, 0]) if 'L_ecran_subs' in data else None
    x_coords = data['x'].flatten() if 'x' in data else None
    
    # Extraire le gap depuis le nom de fichier comme v√©rification
    filename = os.path.basename(data_path)
    gap_from_filename = extract_gap_from_filename(filename)
    
    print(f"\nDonn√©es extraites:")
    print(f"  - Profil ratio: {ratio.shape if ratio is not None else 'Non trouv√©'}")
    print(f"  - Gap (fichier): {gap_true} ¬µm")
    print(f"  - Gap (nom fichier): {gap_from_filename} ¬µm")
    print(f"  - L_ecran: {L_ecran} ¬µm")
    print(f"  - Coordonn√©es x: {x_coords.shape if x_coords is not None else 'Non trouv√©'}")
    
    if ratio is None:
        raise ValueError("Variable 'ratio' non trouv√©e dans le fichier")
    
    return {
        'ratio': ratio,
        'gap_true': gap_true,
        'gap_filename': gap_from_filename,
        'L_ecran': L_ecran,
        'x_coords': x_coords,
        'filename': filename
    }

def extract_gap_from_filename(filename):
    """
    Extrait la valeur du gap depuis le nom de fichier.
    
    Args:
        filename (str): Nom du fichier (ex: "gap_0.0250um_L_10.000um.mat")
        
    Returns:
        float: Valeur du gap en microns
    """
    try:
        # Format: gap_X.XXXXum_L_Y.YYYum.mat
        parts = filename.split('_')
        gap_part = parts[1]  # "0.0250um"
        gap_value = float(gap_part.replace('um', ''))
        return gap_value
    except Exception as e:
        print(f"Erreur extraction gap de {filename}: {e}")
        return None

def predict_gap(model, scaler, ratio_profile):
    """
    Pr√©dit le gap √† partir du profil d'intensit√©.
    
    Args:
        model: Mod√®le PyTorch charg√©
        scaler: StandardScaler pour normalisation
        ratio_profile: Profil d'intensit√© (array 1D)
        
    Returns:
        float: Gap pr√©dit en microns
    """
    print(f"\n=== PR√âDICTION DU GAP ===")
    
    # V√©rifier la taille du profil
    print(f"Taille du profil d'entr√©e: {len(ratio_profile)}")
    
    if len(ratio_profile) != 1000:
        print(f"‚ö†Ô∏è  Attention: Le mod√®le attend 1000 points, re√ßu {len(ratio_profile)}")
        if len(ratio_profile) > 1000:
            ratio_profile = ratio_profile[:1000]
            print(f"Profil tronqu√© √† 1000 points")
        else:
            # Padding avec des z√©ros si n√©cessaire
            ratio_profile = np.pad(ratio_profile, (0, 1000 - len(ratio_profile)), 'constant')
            print(f"Profil compl√©t√© avec des z√©ros √† 1000 points")
    
    # Normalisation
    ratio_normalized = scaler.transform(ratio_profile.reshape(1, -1))
    
    # Conversion en tensor PyTorch
    ratio_tensor = torch.FloatTensor(ratio_normalized)
    
    # Pr√©diction
    with torch.no_grad():
        gap_pred = model(ratio_tensor).item()
    
    print(f"Gap pr√©dit: {gap_pred:.4f} ¬µm")
    
    return gap_pred

def analyze_prediction(gap_true, gap_pred, tolerance=0.01):
    """
    Analyse la qualit√© de la pr√©diction.
    
    Args:
        gap_true (float): Valeur r√©elle du gap
        gap_pred (float): Valeur pr√©dite du gap
        tolerance (float): Tol√©rance acceptable en ¬µm
        
    Returns:
        dict: R√©sultats de l'analyse
    """
    print(f"\n=== ANALYSE DE LA PR√âDICTION ===")
    
    error = gap_pred - gap_true
    abs_error = abs(error)
    rel_error_percent = (abs_error / gap_true) * 100
    
    within_tolerance = abs_error <= tolerance
    
    print(f"Gap r√©el:        {gap_true:.4f} ¬µm")
    print(f"Gap pr√©dit:      {gap_pred:.4f} ¬µm")
    print(f"Erreur:          {error:+.4f} ¬µm")
    print(f"Erreur absolue:  {abs_error:.4f} ¬µm")
    print(f"Erreur relative: {rel_error_percent:.2f}%")
    print(f"Tol√©rance:       ¬±{tolerance:.3f} ¬µm")
    print(f"Dans tol√©rance:  {'‚úÖ OUI' if within_tolerance else '‚ùå NON'}")
    
    # √âvaluation qualitative
    if abs_error <= 0.001:
        quality = "EXCELLENT"
        emoji = "üéâ"
    elif abs_error <= 0.005:
        quality = "TR√àS BON"
        emoji = "‚úÖ"
    elif abs_error <= 0.01:
        quality = "BON"
        emoji = "üëç"
    elif abs_error <= 0.05:
        quality = "ACCEPTABLE"
        emoji = "‚ö†Ô∏è"
    else:
        quality = "PROBL√âMATIQUE"
        emoji = "‚ùå"
    
    print(f"Qualit√©:         {emoji} {quality}")
    
    return {
        'gap_true': gap_true,
        'gap_pred': gap_pred,
        'error': error,
        'abs_error': abs_error,
        'rel_error_percent': rel_error_percent,
        'within_tolerance': within_tolerance,
        'quality': quality
    }

def visualize_results(data, gap_pred, analysis):
    """
    Visualise les r√©sultats de la pr√©diction.
    
    Args:
        data (dict): Donn√©es charg√©es
        gap_pred (float): Gap pr√©dit
        analysis (dict): R√©sultats de l'analyse
    """
    print(f"\n=== VISUALISATION ===")
    
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    # Graphique 1: Profil d'intensit√©
    ax1 = axes[0]
    if data['x_coords'] is not None:
        ax1.plot(data['x_coords'], data['ratio'], 'b-', linewidth=2, label='Profil exp√©rimental')
        ax1.set_xlabel('Position radiale (¬µm)')
    else:
        ax1.plot(data['ratio'], 'b-', linewidth=2, label='Profil exp√©rimental')
        ax1.set_xlabel('Index de position')
    
    ax1.set_ylabel('Intensit√© (ratio)')
    ax1.set_title(f'Profil d\'Intensit√©\n{data["filename"]}')
    ax1.grid(True, alpha=0.3)
    ax1.legend()
    
    # Graphique 2: Comparaison pr√©diction vs r√©alit√©
    ax2 = axes[1]
    
    gaps = [data['gap_true'], gap_pred]
    labels = ['R√©el', 'Pr√©dit']
    colors = ['blue', 'red']
    
    bars = ax2.bar(labels, gaps, color=colors, alpha=0.7)
    ax2.set_ylabel('Gap (¬µm)')
    ax2.set_title('Comparaison Gap R√©el vs Pr√©dit')
    ax2.grid(True, alpha=0.3, axis='y')
    
    # Ajouter les valeurs sur les barres
    for bar, gap in zip(bars, gaps):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                f'{gap:.4f} ¬µm', ha='center', va='bottom', fontweight='bold')
    
    # Ajouter l'erreur
    error_text = f"Erreur: {analysis['error']:+.4f} ¬µm\n"
    error_text += f"Erreur relative: {analysis['rel_error_percent']:.2f}%\n"
    error_text += f"Qualit√©: {analysis['quality']}"
    
    ax2.text(0.02, 0.98, error_text, transform=ax2.transAxes, 
             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    plt.tight_layout()
    
    # Sauvegarder
    output_path = f"test_prediction_{data['filename'].replace('.mat', '.png')}"
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"Graphique sauvegard√©: {output_path}")

def save_results(data, gap_pred, analysis, model_info):
    """
    Sauvegarde les r√©sultats du test.
    
    Args:
        data (dict): Donn√©es d'entr√©e
        gap_pred (float): Gap pr√©dit
        analysis (dict): Analyse de la pr√©diction
        model_info (dict): Informations sur le mod√®le
    """
    results = {
        'test_info': {
            'date': '10-01-2025',
            'model_file': 'model_noise_2percent.pth',
            'data_file': data['filename'],
            'model_noise_level': model_info['noise_level'],
            'model_metrics': model_info['metrics']
        },
        'input_data': {
            'filename': data['filename'],
            'gap_true': float(data['gap_true']),
            'gap_filename': float(data['gap_filename']) if data['gap_filename'] is not None else None,
            'L_ecran': float(data['L_ecran']) if data['L_ecran'] is not None else None,
            'profile_length': len(data['ratio'])
        },
        'prediction': {
            'gap_predicted': float(gap_pred)
        },
        'analysis': analysis
    }
    
    # Sauvegarder en JSON
    output_file = f"test_results_{data['filename'].replace('.mat', '.json')}"
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"R√©sultats sauvegard√©s: {output_file}")

def analyze_data_distribution(data):
    """
    Analyse la distribution des donn√©es pour comprendre les diff√©rences.

    Args:
        data (dict): Donn√©es charg√©es
    """
    print(f"\n=== ANALYSE DE LA DISTRIBUTION DES DONN√âES ===")

    ratio = data['ratio']

    print(f"Statistiques du profil d'intensit√©:")
    print(f"  - Min: {ratio.min():.6f}")
    print(f"  - Max: {ratio.max():.6f}")
    print(f"  - Moyenne: {ratio.mean():.6f}")
    print(f"  - √âcart-type: {ratio.std():.6f}")
    print(f"  - M√©diane: {np.median(ratio):.6f}")

    # V√©rifier s'il y a des valeurs anormales
    if ratio.min() < 0:
        print(f"  ‚ö†Ô∏è  Valeurs n√©gatives d√©tect√©es!")

    if ratio.max() > 10:
        print(f"  ‚ö†Ô∏è  Valeurs tr√®s √©lev√©es d√©tect√©es!")

    # Analyser la forme du profil
    peak_idx = np.argmax(ratio)
    print(f"  - Position du pic: index {peak_idx} ({peak_idx/len(ratio)*100:.1f}%)")
    print(f"  - Valeur du pic: {ratio[peak_idx]:.6f}")

def compare_with_training_data():
    """
    Compare avec les donn√©es d'entra√Ænement pour comprendre les diff√©rences.
    """
    print(f"\n=== COMPARAISON AVEC DONN√âES D'ENTRA√éNEMENT ===")

    # Charger quelques √©chantillons des donn√©es d'entra√Ænement
    training_dir = "data_generation/dataset_small_particle"

    if os.path.exists(training_dir):
        training_files = [f for f in os.listdir(training_dir) if f.endswith('.mat')][:5]

        print(f"Analyse de {len(training_files)} √©chantillons d'entra√Ænement:")

        for filename in training_files:
            try:
                file_path = os.path.join(training_dir, filename)
                data = sio.loadmat(file_path)
                ratio = data['ratio'].flatten()
                gap = float(data['gap'][0, 0])

                print(f"  {filename}:")
                print(f"    Gap: {gap:.4f} ¬µm")
                print(f"    Ratio min/max: {ratio.min():.4f} / {ratio.max():.4f}")
                print(f"    Ratio moyenne: {ratio.mean():.4f}")

            except Exception as e:
                print(f"    Erreur: {e}")
    else:
        print(f"Dossier d'entra√Ænement non trouv√©: {training_dir}")

def main():
    """Fonction principale pour tester le mod√®le."""

    print("="*60)
    print("TEST DU MOD√àLE SUR DONN√âES R√âELLES")
    print("="*60)

    # Chemins des fichiers
    model_path = "Neural_Network_Noise_Robustness_Test_10_01_25/models/model_noise_2percent.pth"
    data_path = "data_generation/dataset/gap_0.0250um_L_10.000um.mat"

    try:
        # 1. Charger le mod√®le
        model, scaler, model_info = load_model_and_scaler(model_path)

        # 2. Charger les donn√©es r√©elles
        data = load_real_data(data_path)

        # 3. Analyser la distribution des donn√©es
        analyze_data_distribution(data)

        # 4. Comparer avec les donn√©es d'entra√Ænement
        compare_with_training_data()

        # 5. Faire la pr√©diction
        gap_pred = predict_gap(model, scaler, data['ratio'])

        # 6. Analyser les r√©sultats
        analysis = analyze_prediction(data['gap_true'], gap_pred)

        # 7. Visualiser
        visualize_results(data, gap_pred, analysis)

        # 8. Sauvegarder les r√©sultats (ignorer l'erreur JSON pour l'instant)
        try:
            save_results(data, gap_pred, analysis, model_info)
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur sauvegarde JSON (ignor√©e): {e}")

        print(f"\n{'='*60}")
        print("TEST TERMIN√â AVEC SUCC√àS")
        print(f"{'='*60}")

        # R√©sum√© final
        print(f"\nüéØ R√âSUM√â:")
        print(f"  Fichier test√©: {data['filename']}")
        print(f"  Gap r√©el: {data['gap_true']:.4f} ¬µm")
        print(f"  Gap pr√©dit: {gap_pred:.4f} ¬µm")
        print(f"  Erreur: {analysis['error']:+.4f} ¬µm ({analysis['rel_error_percent']:.2f}%)")
        print(f"  Qualit√©: {analysis['quality']}")

        # Diagnostic
        print(f"\nüîç DIAGNOSTIC:")
        if gap_pred < 0:
            print(f"  ‚ùå Pr√©diction n√©gative - Probl√®me potentiel:")
            print(f"     ‚Ä¢ Diff√©rence entre donn√©es r√©elles et d'entra√Ænement")
            print(f"     ‚Ä¢ Normalisation inad√©quate")
            print(f"     ‚Ä¢ Mod√®le non adapt√© √† ce type de donn√©es")
        elif abs(analysis['error']) > 0.01:
            print(f"  ‚ö†Ô∏è  Erreur √©lev√©e - Causes possibles:")
            print(f"     ‚Ä¢ Donn√©es hors distribution d'entra√Ænement")
            print(f"     ‚Ä¢ Bruit ou artefacts dans les donn√©es r√©elles")
            print(f"     ‚Ä¢ Calibration n√©cessaire")
        else:
            print(f"  ‚úÖ Pr√©diction acceptable")

    except Exception as e:
        print(f"‚ùå Erreur durant le test: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
Test d'accÃ¨s aux donnÃ©es du dataset 2D

Auteur: Oussama GUELFAA
Date: 06 - 01 - 2025

Ce script teste l'accÃ¨s aux donnÃ©es et valide leur format pour l'entraÃ®nement.
"""

import numpy as np
import pandas as pd
from scipy.io import loadmat
from pathlib import Path
import matplotlib.pyplot as plt
import random

def test_data_loading():
    """
    Teste le chargement de quelques fichiers du dataset.
    """
    print("ğŸ§ª TEST DE CHARGEMENT DES DONNÃ‰ES")
    print("="*40)
    
    dataset_path = Path("data_generation/dataset_2D")
    
    if not dataset_path.exists():
        print("âŒ Dossier dataset_2D non trouvÃ©")
        return False
    
    # Trouver tous les fichiers .mat
    mat_files = list(dataset_path.glob("*.mat"))
    mat_files = [f for f in mat_files if f.name != "labels.mat"]
    
    print(f"ğŸ“ Fichiers trouvÃ©s: {len(mat_files)}")
    
    # Tester quelques fichiers alÃ©atoires
    test_files = random.sample(mat_files, min(5, len(mat_files)))
    
    success_count = 0
    for i, file_path in enumerate(test_files):
        print(f"\nğŸ” Test {i+1}/5: {file_path.name}")
        
        try:
            # Charger le fichier
            data = loadmat(str(file_path))
            
            # VÃ©rifier les clÃ©s attendues
            expected_keys = ['ratio', 'x', 'gap', 'L_ecran_subs']
            missing_keys = [key for key in expected_keys if key not in data]
            
            if missing_keys:
                print(f"   âš ï¸  ClÃ©s manquantes: {missing_keys}")
            else:
                print(f"   âœ… Toutes les clÃ©s prÃ©sentes")
            
            # VÃ©rifier les dimensions
            ratio = data['ratio']
            x = data['x']
            
            print(f"   ğŸ“Š Ratio shape: {ratio.shape}")
            print(f"   ğŸ“Š X shape: {x.shape}")
            print(f"   ğŸ“Š Gap: {data['gap'][0,0]:.4f}")
            print(f"   ğŸ“Š L_ecran: {data['L_ecran_subs'][0,0]:.3f}")
            
            # VÃ©rifier les valeurs
            ratio_flat = ratio.flatten()
            print(f"   ğŸ“ˆ Ratio min/max: {ratio_flat.min():.4f} / {ratio_flat.max():.4f}")
            print(f"   ğŸ“ˆ Ratio mean: {ratio_flat.mean():.4f}")
            
            success_count += 1
            
        except Exception as e:
            print(f"   âŒ Erreur: {e}")
    
    print(f"\nâœ… SuccÃ¨s: {success_count}/{len(test_files)} fichiers")
    return success_count == len(test_files)

def test_data_consistency():
    """
    Teste la cohÃ©rence des donnÃ©es entre fichiers.
    """
    print("\nğŸ” TEST DE COHÃ‰RENCE DES DONNÃ‰ES")
    print("="*40)
    
    dataset_path = Path("data_generation/dataset_2D")
    mat_files = list(dataset_path.glob("*.mat"))
    mat_files = [f for f in mat_files if f.name != "labels.mat"]
    
    # Tester un Ã©chantillon
    test_files = random.sample(mat_files, min(10, len(mat_files)))
    
    shapes = []
    gaps = []
    L_ecrans = []
    
    for file_path in test_files:
        try:
            data = loadmat(str(file_path))
            shapes.append(data['ratio'].shape)
            gaps.append(data['gap'][0,0])
            L_ecrans.append(data['L_ecran_subs'][0,0])
        except:
            continue
    
    # VÃ©rifier la cohÃ©rence des shapes
    unique_shapes = list(set(shapes))
    print(f"ğŸ“ Shapes uniques trouvÃ©es: {unique_shapes}")
    
    if len(unique_shapes) == 1:
        print("   âœ… Toutes les donnÃ©es ont la mÃªme dimension")
    else:
        print("   âš ï¸  Dimensions incohÃ©rentes dÃ©tectÃ©es")
    
    # VÃ©rifier les plages de paramÃ¨tres
    print(f"ğŸ“Š Plage gaps: {min(gaps):.4f} - {max(gaps):.4f}")
    print(f"ğŸ“Š Plage L_ecran: {min(L_ecrans):.3f} - {max(L_ecrans):.3f}")
    
    return len(unique_shapes) == 1

def test_neural_network_format():
    """
    Teste le format des donnÃ©es pour l'entraÃ®nement de rÃ©seaux de neurones.
    """
    print("\nğŸ§  TEST FORMAT RÃ‰SEAUX DE NEURONES")
    print("="*40)
    
    dataset_path = Path("data_generation/dataset_2D")
    mat_files = list(dataset_path.glob("*.mat"))
    mat_files = [f for f in mat_files if f.name != "labels.mat"]
    
    # Charger quelques Ã©chantillons
    sample_files = random.sample(mat_files, min(3, len(mat_files)))
    
    X_samples = []
    y_samples = []
    
    for file_path in sample_files:
        try:
            data = loadmat(str(file_path))
            
            # PrÃ©parer X (features) - ratio d'intensitÃ©
            ratio = data['ratio'].flatten()
            
            # Tronquer Ã  600 points comme recommandÃ©
            if len(ratio) > 600:
                ratio = ratio[:600]
            
            X_samples.append(ratio)
            
            # PrÃ©parer y (targets) - gap et L_ecran
            gap = data['gap'][0,0]
            L_ecran = data['L_ecran_subs'][0,0]
            y_samples.append([gap, L_ecran])
            
        except Exception as e:
            print(f"   âŒ Erreur lors du traitement: {e}")
    
    if X_samples and y_samples:
        X_array = np.array(X_samples)
        y_array = np.array(y_samples)
        
        print(f"ğŸ“Š Format X (features): {X_array.shape}")
        print(f"ğŸ“Š Format y (targets): {y_array.shape}")
        print(f"ğŸ“Š Type X: {X_array.dtype}")
        print(f"ğŸ“Š Type y: {y_array.dtype}")
        
        # Statistiques sur X
        print(f"ğŸ“ˆ X min/max: {X_array.min():.4f} / {X_array.max():.4f}")
        print(f"ğŸ“ˆ X mean/std: {X_array.mean():.4f} / {X_array.std():.4f}")
        
        # Statistiques sur y
        print(f"ğŸ“ˆ Gap min/max: {y_array[:,0].min():.4f} / {y_array[:,0].max():.4f}")
        print(f"ğŸ“ˆ L_ecran min/max: {y_array[:,1].min():.3f} / {y_array[:,1].max():.3f}")
        
        print("âœ… Format compatible avec les rÃ©seaux de neurones")
        return True
    else:
        print("âŒ Impossible de prÃ©parer les donnÃ©es")
        return False

def create_sample_visualization():
    """
    CrÃ©e une visualisation rapide d'un Ã©chantillon.
    """
    print("\nğŸ¨ CRÃ‰ATION D'UNE VISUALISATION Ã‰CHANTILLON")
    print("="*40)
    
    dataset_path = Path("data_generation/dataset_2D")
    mat_files = list(dataset_path.glob("*.mat"))
    mat_files = [f for f in mat_files if f.name != "labels.mat"]
    
    # Prendre un fichier alÃ©atoire
    sample_file = random.choice(mat_files)
    
    try:
        data = loadmat(str(sample_file))
        
        ratio = data['ratio'].flatten()
        x = data['x'].flatten() if 'x' in data else np.arange(len(ratio))
        gap = data['gap'][0,0]
        L_ecran = data['L_ecran_subs'][0,0]
        
        # CrÃ©er le graphique
        plt.figure(figsize=(10, 6))
        plt.plot(x, ratio, 'b-', linewidth=1.5, alpha=0.8)
        plt.title(f'Ã‰chantillon: Gap={gap:.4f}Âµm, L_ecran={L_ecran:.1f}Âµm\n{sample_file.name}')
        plt.xlabel('Position (Âµm)')
        plt.ylabel('Ratio I/Iâ‚€')
        plt.grid(True, alpha=0.3)
        
        # Sauvegarder
        output_path = Path("analysis_scripts/dataset_2D_analysis/outputs_analysis_2D")
        if not output_path.exists():
            output_path.mkdir(parents=True, exist_ok=True)
        
        plt.savefig(output_path / "test_sample_visualization.png", dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… Visualisation sauvegardÃ©e: test_sample_visualization.png")
        print(f"ğŸ“Š Fichier testÃ©: {sample_file.name}")
        print(f"ğŸ“Š Points de donnÃ©es: {len(ratio)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur lors de la visualisation: {e}")
        return False

def main():
    """
    Fonction principale de test.
    """
    print("ğŸ§ª TEST D'ACCÃˆS AU DATASET 2D")
    print("Auteur: Oussama GUELFAA")
    print("Date: 06-01-2025")
    print("="*50)
    
    # Tests sÃ©quentiels
    tests_results = []
    
    # Test 1: Chargement des donnÃ©es
    tests_results.append(test_data_loading())
    
    # Test 2: CohÃ©rence des donnÃ©es
    tests_results.append(test_data_consistency())
    
    # Test 3: Format pour rÃ©seaux de neurones
    tests_results.append(test_neural_network_format())
    
    # Test 4: Visualisation Ã©chantillon
    tests_results.append(create_sample_visualization())
    
    # RÃ©sumÃ© final
    print("\n" + "="*50)
    print("ğŸ“‹ RÃ‰SUMÃ‰ DES TESTS")
    print("-"*30)
    
    test_names = [
        "Chargement des donnÃ©es",
        "CohÃ©rence des donnÃ©es", 
        "Format rÃ©seaux de neurones",
        "Visualisation Ã©chantillon"
    ]
    
    for i, (name, result) in enumerate(zip(test_names, tests_results)):
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"   {i+1}. {name}: {status}")
    
    success_rate = sum(tests_results) / len(tests_results) * 100
    print(f"\nğŸ¯ Taux de succÃ¨s: {success_rate:.0f}%")
    
    if success_rate == 100:
        print("ğŸš€ Tous les tests passÃ©s ! Dataset prÃªt pour l'utilisation.")
    else:
        print("âš ï¸  Certains tests ont Ã©chouÃ©. VÃ©rifiez les donnÃ©es.")
    
    print("="*50)

if __name__ == "__main__":
    main()

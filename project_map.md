# ğŸ—ºï¸ Project Map - Inversion d'Anneaux Neural Networks

**Author:** Oussama GUELFAA  
**Date:** 10 - 01 - 2025

## ğŸ“– Vue d'Ensemble du Projet

Ce projet contient **7 rÃ©seaux de neurones modulaires** pour l'analyse holographique et la prÃ©diction de paramÃ¨tres physiques. Chaque rÃ©seau est organisÃ© comme une unitÃ© indÃ©pendante avec sa propre architecture, configuration et pipeline d'entraÃ®nement.

## ğŸ—ï¸ Architecture Modulaire

```
Inversion_anneaux/
â”œâ”€â”€ ğŸ”¬ Reseau_Gap_Prediction_CNN/          # CNN 1D pour prÃ©diction gap
â”œâ”€â”€ ğŸ”Š Reseau_Noise_Robustness/            # Tests robustesse au bruit
â”œâ”€â”€ ğŸ§ª Reseau_Overfitting_Test/            # Validation surapprentissage
â”œâ”€â”€ ğŸ§  Reseau_Advanced_Regressor/          # RÃ©gresseur avancÃ© avec attention
â”œâ”€â”€ ğŸ”¥ Reseau_Ultra_Specialized/           # Architecture ultra-spÃ©cialisÃ©e
â”œâ”€â”€ âš¡ Reseau_PyTorch_Optimized/           # PyTorch ResNet 1D optimisÃ©
â”œâ”€â”€ ğŸ”§ Reseau_TensorFlow_Alternative/      # Alternative TensorFlow/Keras
â”œâ”€â”€ ğŸ“Š data_generation/                    # DonnÃ©es MATLAB originales
â”œâ”€â”€ ğŸ“‹ project_map.md                      # Cette carte du projet
â””â”€â”€ ğŸ“– README.md                           # Documentation principale
```

## ğŸ¯ RÃ©seaux de Neurones Disponibles

### 1. ğŸ”¬ Reseau_Gap_Prediction_CNN
**Objectif:** PrÃ©diction spÃ©cialisÃ©e du paramÃ¨tre gap  
**Architecture:** CNN 1D avec blocs rÃ©siduels  
**SpÃ©cialitÃ©:** Focus sur gap uniquement, architecture robuste  
**Performance:** RÂ² > 0.99 sur gap  

**Utilisation:**
```bash
cd Reseau_Gap_Prediction_CNN
python run.py --mode train
```

**CaractÃ©ristiques:**
- âœ… CNN 1D avec connexions rÃ©siduelles
- âœ… Global Average Pooling
- âœ… Dropout adaptatif
- âœ… Early stopping automatique

---

### 2. ğŸ”Š Reseau_Noise_Robustness
**Objectif:** Test de robustesse au bruit gaussien  
**Architecture:** RÃ©seau simplifiÃ© pour tests  
**SpÃ©cialitÃ©:** Ã‰valuation progressive 0% Ã  20% de bruit  
**Performance:** RÂ² > 0.8 mÃªme avec 5% de bruit  

**Utilisation:**
```bash
cd Reseau_Noise_Robustness
python run.py
```

**CaractÃ©ristiques:**
- âœ… Tests progressifs de bruit
- âœ… Bruit appliquÃ© uniquement sur train
- âœ… Ã‰valuation tolÃ©rance adaptative
- âœ… Analyse de gÃ©nÃ©ralisation locale

---

### 3. ğŸ§ª Reseau_Overfitting_Test
**Objectif:** Validation capacitÃ© de surapprentissage  
**Architecture:** Simple sans rÃ©gularisation  
**SpÃ©cialitÃ©:** MÃªmes donnÃ©es train/validation  
**Performance:** RÂ² > 0.99 et Loss < 0.001  

**Utilisation:**
```bash
cd Reseau_Overfitting_Test
python run.py
```

**CaractÃ©ristiques:**
- âœ… Test de mÃ©morisation parfaite
- âœ… Architecture simple sans dropout
- âœ… Validation diagnostic
- âœ… Surveillance gradients

---

### 4. ğŸ§  Reseau_Advanced_Regressor
**Objectif:** PrÃ©diction simultanÃ©e gap + L_ecran  
**Architecture:** Multi-tÃªtes avec attention  
**SpÃ©cialitÃ©:** RÃ©solution des 5 problÃ¨mes identifiÃ©s  
**Performance:** RÂ² > 0.8 gap, RÂ² > 0.95 L_ecran  

**Utilisation:**
```bash
cd Reseau_Advanced_Regressor
python run.py
```

**CaractÃ©ristiques:**
- âœ… RÃ©solution systÃ©matique des problÃ¨mes
- âœ… Loss pondÃ©rÃ©e (gap Ã— 30)
- âœ… MÃ©canisme d'attention pour gap
- âœ… Normalisation sÃ©parÃ©e par paramÃ¨tre

---

### 5. ğŸ”¥ Reseau_Ultra_Specialized
**Objectif:** Performance maximale avec ensemble  
**Architecture:** Ensemble de 3 modÃ¨les ultra-profonds  
**SpÃ©cialitÃ©:** Double attention et optimisations extrÃªmes  
**Performance:** RÂ² > 0.85 gap, RÂ² > 0.98 L_ecran  

**Utilisation:**
```bash
cd Reseau_Ultra_Specialized
python run.py
```

**CaractÃ©ristiques:**
- âœ… Ensemble training (3 modÃ¨les)
- âœ… Double attention multiplicative
- âœ… Loss ultra-pondÃ©rÃ©e (gap Ã— 50)
- âœ… TolÃ©rance ultra-prÃ©cise (Â±0.005 Âµm)

---

### 6. âš¡ Reseau_PyTorch_Optimized
**Objectif:** ImplÃ©mentation PyTorch optimisÃ©e  
**Architecture:** ResNet 1D avec optimisations avancÃ©es  
**SpÃ©cialitÃ©:** Techniques PyTorch de pointe  
**Performance:** RÂ² > 0.95 global  

**Utilisation:**
```bash
cd Reseau_PyTorch_Optimized
python run.py
```

**CaractÃ©ristiques:**
- âœ… ResNet 1D avec blocs rÃ©siduels
- âœ… CosineAnnealingWarmRestarts scheduler
- âœ… Optimisations mÃ©moire et parallÃ©lisation
- âœ… Gradient clipping avancÃ©

---

### 7. ğŸ”§ Reseau_TensorFlow_Alternative
**Objectif:** Alternative TensorFlow/Keras  
**Architecture:** Dense 512â†’256â†’128â†’64â†’2  
**SpÃ©cialitÃ©:** API Keras avec callbacks automatiques  
**Performance:** RÂ² > 0.85 global  

**Utilisation:**
```bash
cd Reseau_TensorFlow_Alternative
python run.py
```

**CaractÃ©ristiques:**
- âœ… Architecture Dense spÃ©cifiÃ©e
- âœ… Callbacks Keras automatiques
- âœ… Early stopping et ReduceLROnPlateau
- âœ… Sauvegarde native .h5

## ğŸ“Š Comparaison des Performances

| RÃ©seau | Gap RÂ² | L_ecran RÂ² | SpÃ©cialitÃ© | Temps |
|--------|--------|------------|------------|-------|
| Gap Prediction CNN | >0.99 | - | Gap uniquement | ~5 min |
| Noise Robustness | >0.8* | >0.95* | Robustesse bruit | ~15 min |
| Overfitting Test | >0.99 | >0.99 | Validation diagnostic | ~3 min |
| Advanced Regressor | >0.8 | >0.95 | RÃ©solution problÃ¨mes | ~8 min |
| Ultra Specialized | >0.85 | >0.98 | Performance max | ~20 min |
| PyTorch Optimized | >0.8 | >0.95 | Optimisations PyTorch | ~10 min |
| TensorFlow Alternative | >0.8 | >0.95 | API Keras | ~15 min |

*\* Performance sous 5% de bruit*

## ğŸ¯ Guide de SÃ©lection

### Pour la Production
- **RecommandÃ©:** `Reseau_Advanced_Regressor` ou `Reseau_Ultra_Specialized`
- **Raison:** RÃ©solution systÃ©matique des problÃ¨mes, performance Ã©levÃ©e

### Pour la Recherche
- **Gap uniquement:** `Reseau_Gap_Prediction_CNN`
- **Robustesse:** `Reseau_Noise_Robustness`
- **Diagnostic:** `Reseau_Overfitting_Test`

### Pour le DÃ©veloppement
- **PyTorch:** `Reseau_PyTorch_Optimized`
- **TensorFlow:** `Reseau_TensorFlow_Alternative`

## ğŸ”§ Structure StandardisÃ©e

Chaque rÃ©seau suit la mÃªme organisation :

```
Reseau_XYZ/
â”œâ”€â”€ run.py              # Script autonome principal
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml     # Configuration complÃ¨te
â”œâ”€â”€ models/             # ModÃ¨les entraÃ®nÃ©s (.pth, .h5, .pkl)
â”œâ”€â”€ plots/              # Visualisations et analyses
â”œâ”€â”€ results/            # MÃ©triques et rapports (JSON, CSV)
â”œâ”€â”€ docs/               # Documentation spÃ©cialisÃ©e
â””â”€â”€ README.md           # Guide d'utilisation
```

## ğŸš€ DÃ©marrage Rapide

### Installation Globale
```bash
# DÃ©pendances communes
pip install torch pandas numpy matplotlib seaborn scikit-learn pyyaml scipy joblib

# Pour TensorFlow (optionnel)
pip install tensorflow

# Pour visualisations avancÃ©es (optionnel)
pip install plotly tensorboard
```

### Test Rapide
```bash
# Tester le rÃ©seau le plus robuste
cd Reseau_Advanced_Regressor
python run.py

# Ou tester la performance maximale
cd Reseau_Ultra_Specialized
python run.py
```

## ğŸ“ˆ DonnÃ©es et Formats

### Source Commune
- **Fichier:** `data_generation/all_banque_new_24_01_25_NEW_full.mat`
- **Variables:** L_ecran_subs_vect, gap_sphere_vect, I_subs, I_subs_inc
- **Ã‰chantillons:** 990 profils d'intensitÃ©
- **CaractÃ©ristiques:** 600-1000 points radiaux

### Formats de Sortie
- **ModÃ¨les:** `.pth` (PyTorch), `.h5` (TensorFlow), `.pkl` (Scalers)
- **RÃ©sultats:** `.json` (mÃ©triques), `.csv` (historiques)
- **Visualisations:** `.png` (plots), `.html` (interactifs)

## ğŸ¯ Objectifs et Applications

### Objectifs Scientifiques
- **PrÃ©diction Gap:** 0.025-1.5 Âµm avec RÂ² > 0.8
- **PrÃ©diction L_ecran:** 6.0-14.0 Âµm avec RÂ² > 0.95
- **Robustesse:** Performance maintenue sous bruit
- **GÃ©nÃ©ralisation:** Validation sur donnÃ©es sÃ©parÃ©es

### Applications Pratiques
- **Holographie ExpÃ©rimentale:** Inversion de paramÃ¨tres en temps rÃ©el
- **ContrÃ´le QualitÃ©:** Validation de mesures holographiques
- **Optimisation:** Calibrage d'instruments optiques
- **Recherche:** DÃ©veloppement de nouvelles techniques

## ğŸ Conclusion

Ce projet offre une **suite complÃ¨te de rÃ©seaux de neurones modulaires** pour l'analyse holographique. Chaque rÃ©seau est **autonome, documentÃ© et prÃªt Ã  l'emploi**. La structure modulaire permet de :

- âœ… **SÃ©lectionner** le rÃ©seau optimal selon les besoins
- âœ… **Comparer** diffÃ©rentes approches facilement
- âœ… **Archiver** chaque rÃ©seau indÃ©pendamment
- âœ… **DÃ©ployer** en production rapidement
- âœ… **Maintenir** et **Ã©tendre** le projet efficacement

**Chaque rÃ©seau peut Ãªtre zippÃ© et utilisÃ© comme unitÃ© indÃ©pendante !** ğŸš€

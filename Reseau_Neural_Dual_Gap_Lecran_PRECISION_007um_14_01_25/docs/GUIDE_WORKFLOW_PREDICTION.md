# ğŸ” GUIDE DÃ‰TAILLÃ‰ DU WORKFLOW DE PRÃ‰DICTION

**Auteur:** Oussama GUELFAA  
**Date:** 19-06-2025  
**Test:** 2392 Ã©chantillons

---

## ğŸ“‹ **WORKFLOW COMPLET Ã‰TAPE PAR Ã‰TAPE**

### **ğŸ”§ 1. CHARGEMENT ET PRÃ‰PARATION DES DONNÃ‰ES**

#### **A. Chargement du ModÃ¨le depuis le fichier .pth**

```python
# Ligne 69: Chargement du checkpoint
checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)

# Ligne 71-73: Reconstruction du modÃ¨le
model = DualParameterPredictor(input_size=600)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()
```

**ğŸ“Š Contenu du fichier .pth :**
- `model_state_dict`: Poids du rÃ©seau neuronal (1,318,882 paramÃ¨tres)
- `config`: Configuration d'entraÃ®nement
- `training_info`: Informations d'entraÃ®nement (300 epochs)
- `test_metrics`: MÃ©triques de performance (Gap RÂ²: 0.9953, L_ecran RÂ²: 0.9891)

#### **B. Division des DonnÃ©es (Splits 70/16/14)**

```python
# Ligne 82-89: Configuration des splits
config = {
    'data_processing': {
        'data_splits': {'train': 0.70, 'validation': 0.16, 'test': 0.14}
    }
}
```

**ğŸ“ˆ RÃ©sultat de la division :**
- **Dataset total :** 17,080 Ã©chantillons (augmentÃ©s)
- **Train :** 11,955 Ã©chantillons (70%)
- **Validation :** 2,733 Ã©chantillons (16%)
- **Test :** 2,392 Ã©chantillons (14%) â† **Notre cible ~2400**

#### **C. RÃ´le du DualDataLoader et Normalisation**

```python
# Ligne 78: Initialisation
data_loader = DualDataLoader()

# Ligne 91: Pipeline complet
pipeline_result = data_loader.get_complete_pipeline(config)

# Ligne 94-95: RÃ©cupÃ©ration des donnÃ©es NON normalisÃ©es
X_test = pipeline_result['raw_data'][2]  # Profils [2392, 600]
y_test = pipeline_result['raw_data'][5]  # Labels [2392, 2]
```

**ğŸ”§ Fonctions du DualDataLoader :**
1. **Chargement :** Cache `augmented_dataset_advanced.npz`
2. **SÃ©paration stricte :** Aucun chevauchement entre train/val/test
3. **Normalisation :** StandardScaler pour profils et scaling sÃ©parÃ© pour gap/L_ecran
4. **Scalers sauvegardÃ©s :** `input_scaler`, `gap_scaler`, `L_ecran_scaler`

---

### **âš™ï¸ 2. PROCESSUS DE PRÃ‰DICTION**

#### **A. Traitement d'un Ã‰chantillon [600 points]**

```python
# Ligne 129-130: Pour chaque Ã©chantillon
profile = X_test[i]  # Shape: [600] - Profil d'intensitÃ© radial
gap_pred, L_ecran_pred = predict_sample(model, profile, data_loader)
```

**ğŸ“Š Exemple concret d'un profil :**
- **Input :** `profile = [0.234, 0.456, 0.789, ..., 0.123]` (600 valeurs)
- **ReprÃ©sente :** IntensitÃ© holographique en fonction du rayon (0-6 Âµm)

#### **B. Ã‰tapes Normalisation â†’ PrÃ©diction â†’ DÃ©normalisation**

```python
# Ligne 40: Ã‰TAPE 1 - Normalisation
profile_scaled = data_loader.input_scaler.transform(profile.reshape(1, -1))
# Exemple: [0.234, 0.456, ...] â†’ [-1.23, 0.45, ...] (standardisÃ©)

# Ligne 43-45: Ã‰TAPE 2 - PrÃ©diction
with torch.no_grad():
    input_tensor = torch.FloatTensor(profile_scaled)  # [1, 600]
    prediction_scaled = model(input_tensor).numpy()  # [1, 2]

# Ligne 48: Ã‰TAPE 3 - DÃ©normalisation
prediction_original = data_loader.inverse_transform_predictions(prediction_scaled)
```

**ğŸ”¢ Exemple de transformation :**
```
Input brut:     [0.234, 0.456, 0.789, ..., 0.123]
â†“ Normalisation
Input normalisÃ©: [-1.23, 0.45, 1.67, ..., -0.89]
â†“ RÃ©seau neuronal
Output normalisÃ©: [-0.567, 1.234]
â†“ DÃ©normalisation
Output final:    [0.0847, 10.45] â†’ Gap: 0.0847Âµm, L_ecran: 10.45Âµm
```

#### **C. Extraction des PrÃ©dictions Gap et L_ecran**

```python
# Ligne 50-51: Extraction des valeurs
gap_pred = prediction_original[0, 0]      # Premier Ã©lÃ©ment: Gap en Âµm
L_ecran_pred = prediction_original[0, 1]  # DeuxiÃ¨me Ã©lÃ©ment: L_ecran en Âµm
```

---

### **ğŸ“Š 3. CALCUL DES MÃ‰TRIQUES**

#### **A. MÃ©triques RÂ², MAE, RMSE**

```python
# Ligne 146-154: Calcul des mÃ©triques
gap_r2 = r2_score(true_gap, predictions_gap)
L_ecran_r2 = r2_score(true_L_ecran, predictions_L_ecran)
combined_r2 = (gap_r2 + L_ecran_r2) / 2

gap_mae = mean_absolute_error(true_gap, predictions_gap)
gap_rmse = np.sqrt(mean_squared_error(true_gap, predictions_gap))
```

**ğŸ“ˆ Formules utilisÃ©es :**
- **RÂ² :** `1 - (SS_res / SS_tot)` oÃ¹ SS_res = Î£(y_true - y_pred)Â², SS_tot = Î£(y_true - y_mean)Â²
- **MAE :** `Î£|y_true - y_pred| / n`
- **RMSE :** `âˆš(Î£(y_true - y_pred)Â² / n)`

**ğŸ¯ RÃ©sultats obtenus :**
- **Gap RÂ² :** 0.9944 (99.44% de variance expliquÃ©e)
- **Gap MAE :** 0.0035 Âµm (erreur moyenne absolue)
- **Gap RMSE :** 0.0043 Âµm (erreur quadratique moyenne)

#### **B. Analyse de TolÃ©rance**

```python
# Ligne 157-164: Analyse de tolÃ©rance
gap_tolerance = 0.01  # Âµm
L_ecran_tolerance = 0.1  # Âµm

gap_within_tolerance = np.sum(np.abs(predictions_gap - true_gap) <= gap_tolerance)
gap_accuracy = gap_within_tolerance / len(X_test)
```

**ğŸ¯ Signification des tolÃ©rances :**
- **Gap Â±0.01Âµm :** PrÃ©cision requise pour applications industrielles
- **L_ecran Â±0.1Âµm :** TolÃ©rance acceptable pour distance Ã©cran-objet

**ğŸ“Š RÃ©sultats de tolÃ©rance :**
- **Gap :** 2368/2392 (99.0%) dans Â±0.01Âµm
- **L_ecran :** 2245/2392 (93.9%) dans Â±0.1Âµm

#### **C. Statistiques d'Erreurs (Max, Min, MÃ©diane)**

```python
# Ligne 185-190: Statistiques d'erreurs
gap_errors = np.abs(predictions_gap - true_gap)
L_ecran_errors = np.abs(predictions_L_ecran - true_L_ecran)

print(f"Gap - Max: {gap_errors.max():.4f} Âµm, Min: {gap_errors.min():.4f} Âµm")
print(f"MÃ©diane: {np.median(gap_errors):.4f} Âµm")
```

**ğŸ“ˆ Signification des statistiques :**
- **Max :** Pire erreur observÃ©e (Gap: 0.0110Âµm, L_ecran: 0.1644Âµm)
- **Min :** Meilleure prÃ©diction (0.0000Âµm pour les deux)
- **MÃ©diane :** Erreur typique (Gap: 0.0031Âµm, L_ecran: 0.0245Âµm)

---

## ğŸ†• **COMMENT TESTER SUR DE NOUVELLES DONNÃ‰ES**

### **ğŸ“‹ Ã‰tapes pour Nouvelles DonnÃ©es :**

#### **1. PrÃ©paration des DonnÃ©es**
```python
# Vos nouvelles donnÃ©es doivent Ãªtre au format:
# X_new: [n_samples, 600] - Profils d'intensitÃ© radiaux
# y_new: [n_samples, 2] - Labels [gap, L_ecran] (optionnel pour validation)

# Exemple:
X_new = np.load('mes_nouveaux_profils.npy')  # Shape: [100, 600]
y_new = np.load('mes_nouveaux_labels.npy')   # Shape: [100, 2] (optionnel)
```

#### **2. Chargement du ModÃ¨le et DataLoader**
```python
# Charger le modÃ¨le entraÃ®nÃ©
model, _, _, data_loader = load_model_and_data()
```

#### **3. PrÃ©dictions sur Nouvelles DonnÃ©es**
```python
predictions_gap = []
predictions_L_ecran = []

for i in range(len(X_new)):
    profile = X_new[i]
    gap_pred, L_ecran_pred = predict_sample(model, profile, data_loader)
    predictions_gap.append(gap_pred)
    predictions_L_ecran.append(L_ecran_pred)

# Conversion en arrays
predictions_gap = np.array(predictions_gap)
predictions_L_ecran = np.array(predictions_L_ecran)
```

#### **4. Ã‰valuation (si labels disponibles)**
```python
if y_new is not None:
    gap_r2 = r2_score(y_new[:, 0], predictions_gap)
    L_ecran_r2 = r2_score(y_new[:, 1], predictions_L_ecran)
    print(f"Gap RÂ²: {gap_r2:.4f}, L_ecran RÂ²: {L_ecran_r2:.4f}")
```

#### **5. Sauvegarde des RÃ©sultats**
```python
results = {
    'predictions': {
        'gap': predictions_gap.tolist(),
        'L_ecran': predictions_L_ecran.tolist()
    }
}

with open('mes_predictions.json', 'w') as f:
    json.dump(results, f, indent=2)
```

---

## âœ… **POINTS CLÃ‰S Ã€ RETENIR**

1. **Normalisation Cruciale :** Toujours utiliser les mÃªmes scalers d'entraÃ®nement
2. **Format des DonnÃ©es :** Profils de 600 points (intensitÃ© radiale 0-6Âµm)
3. **Mode Ã‰valuation :** `model.eval()` et `torch.no_grad()` pour l'infÃ©rence
4. **DÃ©normalisation :** Obligatoire pour obtenir les valeurs physiques rÃ©elles
5. **TolÃ©rances :** Â±0.01Âµm pour gap, Â±0.1Âµm pour L_ecran selon spÃ©cifications

Le workflow est **robuste** et **reproductible** avec des performances **exceptionnelles** validÃ©es sur 2392 Ã©chantillons ! ğŸ‰

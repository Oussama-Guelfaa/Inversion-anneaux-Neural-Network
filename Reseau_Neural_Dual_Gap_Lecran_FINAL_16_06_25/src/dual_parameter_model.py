#!/usr/bin/env python3
"""
Mod√®le de R√©seau de Neurones pour Pr√©diction Conjointe Gap + L_ecran

Auteur: Oussama GUELFAA
Date: 06 - 01 - 2025

Ce module impl√©mente un r√©seau de neurones robuste pour pr√©dire
simultan√©ment les param√®tres gap et L_ecran √† partir de profils
d'intensit√© holographiques.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt
import seaborn as sns

class DualParameterPredictor(nn.Module):
    """
    R√©seau de neurones pour pr√©diction conjointe gap + L_ecran.
    
    Architecture inspir√©e du mod√®le robuste gap-only mais adapt√©e
    pour sortie dual avec techniques de r√©gularisation avanc√©es.
    """
    
    def __init__(self, input_size=600, dropout_rate=0.2):
        """
        Initialise le mod√®le dual.
        
        Args:
            input_size (int): Taille d'entr√©e (600 points recommand√©)
            dropout_rate (float): Taux de dropout pour r√©gularisation
        """
        super(DualParameterPredictor, self).__init__()
        
        # Couche d'entr√©e - 512 neurones
        self.fc1 = nn.Linear(input_size, 512)
        self.bn1 = nn.BatchNorm1d(512)
        self.dropout1 = nn.Dropout(dropout_rate)
        
        # Couche cach√©e 1 - 256 neurones
        self.fc2 = nn.Linear(512, 256)
        self.bn2 = nn.BatchNorm1d(256)
        self.dropout2 = nn.Dropout(dropout_rate)
        
        # Couche cach√©e 2 - 128 neurones
        self.fc3 = nn.Linear(256, 128)
        self.bn3 = nn.BatchNorm1d(128)
        self.dropout3 = nn.Dropout(dropout_rate)
        
        # Couche cach√©e 3 - 64 neurones
        self.fc4 = nn.Linear(128, 64)
        self.bn4 = nn.BatchNorm1d(64)
        self.dropout4 = nn.Dropout(dropout_rate * 0.5)  # Dropout r√©duit
        
        # Couche de sortie - 2 param√®tres [gap, L_ecran]
        self.fc_out = nn.Linear(64, 2)
        
        # Initialisation des poids
        self._initialize_weights()
    
    def _initialize_weights(self):
        """Initialise les poids avec Xavier/Glorot initialization."""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)
    
    def forward(self, x):
        """
        Forward pass du mod√®le.
        
        Args:
            x (torch.Tensor): Profils d'intensit√© [batch_size, 600]
        
        Returns:
            torch.Tensor: Pr√©dictions [batch_size, 2] o√π [:, 0] = gap, [:, 1] = L_ecran
        """
        # Couche 1: 600 ‚Üí 512
        x = F.relu(self.bn1(self.fc1(x)))
        x = self.dropout1(x)
        
        # Couche 2: 512 ‚Üí 256
        x = F.relu(self.bn2(self.fc2(x)))
        x = self.dropout2(x)
        
        # Couche 3: 256 ‚Üí 128
        x = F.relu(self.bn3(self.fc3(x)))
        x = self.dropout3(x)
        
        # Couche 4: 128 ‚Üí 64
        x = F.relu(self.bn4(self.fc4(x)))
        x = self.dropout4(x)
        
        # Sortie: 64 ‚Üí 2 (gap, L_ecran)
        x = self.fc_out(x)
        
        return x

class DualParameterLoss(nn.Module):
    """
    Loss function personnalis√©e pour pr√©diction dual avec pond√©ration.
    """
    
    def __init__(self, gap_weight=1.0, L_ecran_weight=1.0):
        """
        Initialise la loss function dual.
        
        Args:
            gap_weight (float): Poids pour la loss du gap
            L_ecran_weight (float): Poids pour la loss de L_ecran
        """
        super(DualParameterLoss, self).__init__()
        self.gap_weight = gap_weight
        self.L_ecran_weight = L_ecran_weight
        self.mse = nn.MSELoss()
    
    def forward(self, predictions, targets):
        """
        Calcule la loss pond√©r√©e.
        
        Args:
            predictions (torch.Tensor): Pr√©dictions [batch_size, 2]
            targets (torch.Tensor): Vraies valeurs [batch_size, 2]
        
        Returns:
            torch.Tensor: Loss totale pond√©r√©e
        """
        # S√©parer gap et L_ecran
        pred_gap = predictions[:, 0]
        pred_L_ecran = predictions[:, 1]
        true_gap = targets[:, 0]
        true_L_ecran = targets[:, 1]
        
        # Calculer les losses s√©par√©es
        loss_gap = self.mse(pred_gap, true_gap)
        loss_L_ecran = self.mse(pred_L_ecran, true_L_ecran)
        
        # Loss totale pond√©r√©e
        total_loss = (self.gap_weight * loss_gap + 
                     self.L_ecran_weight * loss_L_ecran)
        
        return total_loss, loss_gap, loss_L_ecran

class DualParameterMetrics:
    """
    Classe pour calculer les m√©triques de performance dual.
    """
    
    def __init__(self, gap_tolerance=0.01, L_ecran_tolerance=0.1):
        """
        Initialise les m√©triques.
        
        Args:
            gap_tolerance (float): Tol√©rance pour accuracy gap (¬µm)
            L_ecran_tolerance (float): Tol√©rance pour accuracy L_ecran (¬µm)
        """
        self.gap_tolerance = gap_tolerance
        self.L_ecran_tolerance = L_ecran_tolerance
    
    def calculate_metrics(self, predictions, targets):
        """
        Calcule toutes les m√©triques de performance.
        
        Args:
            predictions (np.array): Pr√©dictions [n_samples, 2]
            targets (np.array): Vraies valeurs [n_samples, 2]
        
        Returns:
            dict: Dictionnaire des m√©triques
        """
        # S√©parer les param√®tres
        pred_gap = predictions[:, 0]
        pred_L_ecran = predictions[:, 1]
        true_gap = targets[:, 0]
        true_L_ecran = targets[:, 1]
        
        # M√©triques pour gap
        gap_r2 = r2_score(true_gap, pred_gap)
        gap_mae = mean_absolute_error(true_gap, pred_gap)
        gap_mse = mean_squared_error(true_gap, pred_gap)
        gap_rmse = np.sqrt(gap_mse)
        gap_accuracy = np.mean(np.abs(pred_gap - true_gap) <= self.gap_tolerance)
        
        # M√©triques pour L_ecran
        L_ecran_r2 = r2_score(true_L_ecran, pred_L_ecran)
        L_ecran_mae = mean_absolute_error(true_L_ecran, pred_L_ecran)
        L_ecran_mse = mean_squared_error(true_L_ecran, pred_L_ecran)
        L_ecran_rmse = np.sqrt(L_ecran_mse)
        L_ecran_accuracy = np.mean(np.abs(pred_L_ecran - true_L_ecran) <= self.L_ecran_tolerance)
        
        # M√©triques combin√©es
        combined_r2 = (gap_r2 + L_ecran_r2) / 2
        combined_accuracy = (gap_accuracy + L_ecran_accuracy) / 2
        
        return {
            # M√©triques gap
            'gap_r2': gap_r2,
            'gap_mae': gap_mae,
            'gap_mse': gap_mse,
            'gap_rmse': gap_rmse,
            'gap_accuracy': gap_accuracy,
            
            # M√©triques L_ecran
            'L_ecran_r2': L_ecran_r2,
            'L_ecran_mae': L_ecran_mae,
            'L_ecran_mse': L_ecran_mse,
            'L_ecran_rmse': L_ecran_rmse,
            'L_ecran_accuracy': L_ecran_accuracy,
            
            # M√©triques combin√©es
            'combined_r2': combined_r2,
            'combined_accuracy': combined_accuracy
        }
    
    def print_metrics(self, metrics, title="Performance Metrics"):
        """
        Affiche les m√©triques de fa√ßon format√©e.
        
        Args:
            metrics (dict): M√©triques calcul√©es
            title (str): Titre de l'affichage
        """
        print(f"\nüìä {title}")
        print("="*50)
        
        print(f"üéØ GAP METRICS:")
        print(f"   R¬≤ Score: {metrics['gap_r2']:.4f}")
        print(f"   MAE: {metrics['gap_mae']:.4f} ¬µm")
        print(f"   RMSE: {metrics['gap_rmse']:.4f} ¬µm")
        print(f"   Accuracy (¬±{self.gap_tolerance}¬µm): {metrics['gap_accuracy']:.1%}")
        
        print(f"\nüéØ L_ECRAN METRICS:")
        print(f"   R¬≤ Score: {metrics['L_ecran_r2']:.4f}")
        print(f"   MAE: {metrics['L_ecran_mae']:.4f} ¬µm")
        print(f"   RMSE: {metrics['L_ecran_rmse']:.4f} ¬µm")
        print(f"   Accuracy (¬±{self.L_ecran_tolerance}¬µm): {metrics['L_ecran_accuracy']:.1%}")
        
        print(f"\nüéØ COMBINED METRICS:")
        print(f"   Combined R¬≤: {metrics['combined_r2']:.4f}")
        print(f"   Combined Accuracy: {metrics['combined_accuracy']:.1%}")
        
        # V√©rification des objectifs
        gap_success = metrics['gap_accuracy'] >= 0.90
        L_ecran_success = metrics['L_ecran_accuracy'] >= 0.90
        r2_success = metrics['combined_r2'] >= 0.80
        
        print(f"\n‚úÖ OBJECTIFS:")
        print(f"   Gap Accuracy > 90%: {'‚úÖ' if gap_success else '‚ùå'}")
        print(f"   L_ecran Accuracy > 90%: {'‚úÖ' if L_ecran_success else '‚ùå'}")
        print(f"   Combined R¬≤ > 80%: {'‚úÖ' if r2_success else '‚ùå'}")

class DualParameterVisualizer:
    """
    Classe pour visualiser les r√©sultats du mod√®le dual.
    """
    
    def __init__(self, save_dir="plots/"):
        """
        Initialise le visualiseur.
        
        Args:
            save_dir (str): Dossier de sauvegarde des plots
        """
        self.save_dir = save_dir
        try:
            plt.style.use('seaborn-v0_8')
        except:
            try:
                plt.style.use('seaborn')
            except:
                pass  # Utiliser le style par d√©faut
        sns.set_palette("husl")
    
    def plot_training_curves(self, history, save_name="training_curves.png"):
        """
        Trace les courbes d'entra√Ænement.
        
        Args:
            history (dict): Historique d'entra√Ænement
            save_name (str): Nom du fichier de sauvegarde
        """
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Courbes d\'Entra√Ænement - Pr√©diction Dual Gap + L_ecran', 
                    fontsize=16, fontweight='bold')
        
        epochs = range(1, len(history['train_loss']) + 1)
        
        # Loss totale
        axes[0, 0].plot(epochs, history['train_loss'], 'b-', label='Train Loss')
        axes[0, 0].plot(epochs, history['val_loss'], 'r-', label='Val Loss')
        axes[0, 0].set_title('Loss Totale')
        axes[0, 0].set_xlabel('Epochs')
        axes[0, 0].set_ylabel('MSE Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # R¬≤ Gap
        axes[0, 1].plot(epochs, history['train_gap_r2'], 'b-', label='Train R¬≤ Gap')
        axes[0, 1].plot(epochs, history['val_gap_r2'], 'r-', label='Val R¬≤ Gap')
        axes[0, 1].axhline(y=0.8, color='green', linestyle='--', label='Target R¬≤=0.8')
        axes[0, 1].set_title('R¬≤ Score - Gap')
        axes[0, 1].set_xlabel('Epochs')
        axes[0, 1].set_ylabel('R¬≤ Score')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # R¬≤ L_ecran
        axes[1, 0].plot(epochs, history['train_L_ecran_r2'], 'b-', label='Train R¬≤ L_ecran')
        axes[1, 0].plot(epochs, history['val_L_ecran_r2'], 'r-', label='Val R¬≤ L_ecran')
        axes[1, 0].axhline(y=0.8, color='green', linestyle='--', label='Target R¬≤=0.8')
        axes[1, 0].set_title('R¬≤ Score - L_ecran')
        axes[1, 0].set_xlabel('Epochs')
        axes[1, 0].set_ylabel('R¬≤ Score')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # Learning Rate
        if 'learning_rate' in history:
            axes[1, 1].plot(epochs, history['learning_rate'], 'g-')
            axes[1, 1].set_title('Learning Rate')
            axes[1, 1].set_xlabel('Epochs')
            axes[1, 1].set_ylabel('Learning Rate')
            axes[1, 1].set_yscale('log')
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f"{self.save_dir}/{save_name}", dpi=300, bbox_inches='tight')
        plt.close()
    
    def plot_predictions_scatter(self, predictions, targets, save_name="predictions_scatter.png"):
        """
        Trace les scatter plots des pr√©dictions vs vraies valeurs.
        
        Args:
            predictions (np.array): Pr√©dictions [n_samples, 2]
            targets (np.array): Vraies valeurs [n_samples, 2]
            save_name (str): Nom du fichier de sauvegarde
        """
        fig, axes = plt.subplots(1, 2, figsize=(16, 6))
        fig.suptitle('Pr√©dictions vs Vraies Valeurs', fontsize=16, fontweight='bold')
        
        # Scatter plot Gap
        axes[0].scatter(targets[:, 0], predictions[:, 0], alpha=0.6, s=20)
        axes[0].plot([targets[:, 0].min(), targets[:, 0].max()], 
                    [targets[:, 0].min(), targets[:, 0].max()], 'r--', linewidth=2)
        axes[0].set_xlabel('Gap Vrai (¬µm)')
        axes[0].set_ylabel('Gap Pr√©dit (¬µm)')
        axes[0].set_title('Pr√©diction Gap')
        axes[0].grid(True, alpha=0.3)
        
        # Calculer R¬≤ pour gap
        gap_r2 = r2_score(targets[:, 0], predictions[:, 0])
        axes[0].text(0.05, 0.95, f'R¬≤ = {gap_r2:.4f}', 
                    transform=axes[0].transAxes, fontsize=12,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
        
        # Scatter plot L_ecran
        axes[1].scatter(targets[:, 1], predictions[:, 1], alpha=0.6, s=20)
        axes[1].plot([targets[:, 1].min(), targets[:, 1].max()], 
                    [targets[:, 1].min(), targets[:, 1].max()], 'r--', linewidth=2)
        axes[1].set_xlabel('L_ecran Vrai (¬µm)')
        axes[1].set_ylabel('L_ecran Pr√©dit (¬µm)')
        axes[1].set_title('Pr√©diction L_ecran')
        axes[1].grid(True, alpha=0.3)
        
        # Calculer R¬≤ pour L_ecran
        L_ecran_r2 = r2_score(targets[:, 1], predictions[:, 1])
        axes[1].text(0.05, 0.95, f'R¬≤ = {L_ecran_r2:.4f}', 
                    transform=axes[1].transAxes, fontsize=12,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
        
        plt.tight_layout()
        plt.savefig(f"{self.save_dir}/{save_name}", dpi=300, bbox_inches='tight')
        plt.close()


def test_model_architecture():
    """
    Test rapide de l'architecture du mod√®le.
    """
    print("üß™ Test de l'architecture DualParameterPredictor")
    print("="*50)
    
    # Cr√©er le mod√®le
    model = DualParameterPredictor(input_size=600)
    
    # Test avec donn√©es factices
    batch_size = 32
    input_size = 600
    
    # Donn√©es d'entr√©e factices
    x = torch.randn(batch_size, input_size)
    
    # Forward pass
    with torch.no_grad():
        predictions = model(x)
    
    print(f"‚úÖ Input shape: {x.shape}")
    print(f"‚úÖ Output shape: {predictions.shape}")
    print(f"‚úÖ Expected output shape: ({batch_size}, 2)")
    
    # V√©rifier que la sortie a la bonne forme
    assert predictions.shape == (batch_size, 2), f"Erreur: forme attendue ({batch_size}, 2), obtenue {predictions.shape}"
    
    print(f"‚úÖ Test r√©ussi ! Le mod√®le fonctionne correctement.")
    
    # Afficher le nombre de param√®tres
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"üìä Param√®tres totaux: {total_params:,}")
    print(f"üìä Param√®tres entra√Ænables: {trainable_params:,}")


if __name__ == "__main__":
    test_model_architecture()

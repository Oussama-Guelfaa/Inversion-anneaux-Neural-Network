# Configuration for Overfitting Validation Test
# Author: Oussama GUELFAA
# Date: 10 - 01 - 2025

experiment:
  name: "Overfitting_Validation_Test"
  description: "Test de validation du surapprentissage avec mêmes données train/validation"
  
test_type: "overfitting_validation"
purpose: "Vérifier la capacité du modèle à mémoriser parfaitement les données d'entraînement"

model:
  name: "OverfittingTestCNN"
  type: "Simple_Dense_Network"
  input_size: 600  # Profils tronqués
  output_size: 1
  
architecture:
  # Architecture simple sans régularisation pour favoriser l'overfitting
  dense_layers:
    - size: 256
      activation: "ReLU"
      dropout: 0.0  # Pas de dropout pour overfitting
      batch_norm: false  # Pas de batch norm
    - size: 128
      activation: "ReLU"
      dropout: 0.0
      batch_norm: false
    - size: 64
      activation: "ReLU"
      dropout: 0.0
      batch_norm: false
    - size: 1
      activation: "Linear"

training:
  # Paramètres optimisés pour overfitting
  batch_size: 8  # Petit batch size
  epochs: 150  # Beaucoup d'epochs
  learning_rate: 0.0001  # Learning rate faible
  optimizer: "Adam"
  loss_function: "MSE"
  weight_decay: 0.0  # Pas de régularisation
  
  # Pas d'early stopping pour permettre l'overfitting
  early_stopping:
    enable: false
    patience: 999
    min_delta: 0.0
  
  # Scheduler désactivé
  lr_scheduler:
    enable: false

data:
  # Utiliser les mêmes données pour train et validation
  use_same_data_for_train_val: true
  train_split: 1.0  # Toutes les données pour train
  val_split: 1.0    # Les mêmes données pour validation
  test_split: 0.0   # Pas de données de test séparées
  
  # Pas de normalisation pour voir l'overfitting pur
  normalization: "StandardScaler"
  shuffle: true
  
validation_criteria:
  # Critères de validation pour overfitting réussi
  target_train_r2: 0.99  # R² proche de 1.0 sur train
  target_val_r2: 0.99    # R² proche de 1.0 sur validation (mêmes données)
  target_train_loss: 0.001  # Loss très faible sur train
  target_val_loss: 0.001    # Loss très faible sur validation
  
  # Tolérance pour considérer l'overfitting comme réussi
  r2_tolerance: 0.01
  loss_tolerance: 0.005

monitoring:
  # Surveillance détaillée de l'overfitting
  log_frequency: 5  # Log toutes les 5 epochs
  plot_frequency: 10  # Plot toutes les 10 epochs
  
  metrics_to_track:
    - "train_loss"
    - "val_loss"
    - "train_r2"
    - "val_r2"
    - "learning_rate"
    - "gradient_norm"

paths:
  data_file: "../data_generation/all_banque_new_24_01_25_NEW_full.mat"
  model_save: "models/overfitting_test_model.pth"
  plots_dir: "plots/"
  results_dir: "results/"

visualization:
  generate_plots: true
  plot_types:
    - "training_curves"
    - "loss_convergence"
    - "r2_evolution"
    - "predictions_vs_true"
    - "residuals_analysis"
    - "learning_rate_schedule"
  
  # Graphiques spéciaux pour overfitting
  overfitting_plots:
    - "train_val_gap_analysis"
    - "perfect_fit_verification"
    - "memorization_check"

analysis:
  # Analyses spécifiques à l'overfitting
  memorization_analysis:
    enable: true
    check_individual_predictions: true
    tolerance_for_perfect_fit: 0.001
  
  convergence_analysis:
    enable: true
    check_loss_plateau: true
    minimum_epochs_for_convergence: 50
  
  gradient_analysis:
    enable: true
    track_gradient_norms: true
    check_gradient_explosion: true

expected_results:
  # Résultats attendus pour validation d'overfitting
  train_r2_final: ">= 0.99"
  val_r2_final: ">= 0.99"
  train_loss_final: "<= 0.001"
  val_loss_final: "<= 0.001"
  
  # Indicateurs de surapprentissage réussi
  perfect_memorization: true
  near_zero_loss: true
  high_r2_score: true
  
success_criteria:
  # Critères pour considérer le test comme réussi
  - "R² train et validation > 0.99"
  - "Loss train et validation < 0.001"
  - "Convergence stable sans oscillations"
  - "Mémorisation parfaite des données d'entraînement"
  - "Pas de divergence ou d'instabilité"

notes:
  purpose: "Ce test valide que le modèle peut apprendre parfaitement les données quand on lui en donne la capacité"
  interpretation: "Un échec indique un problème dans l'architecture ou l'entraînement"
  next_steps: "Si réussi, tester la généralisation avec données séparées"

# Configuration for Advanced Regressor with Attention
# Author: Oussama GUELFAA
# Date: 10 - 01 - 2025

experiment:
  name: "Advanced_Regressor_with_Attention"
  description: "Régresseur avancé avec mécanisme d'attention pour prédiction gap et L_ecran"
  version: "06_06_25"

model:
  name: "AdvancedRegressor"
  type: "Multi_Head_Attention_Regressor"
  input_size: 600  # Profils tronqués
  output_size: 2   # gap et L_ecran
  
architecture:
  # Feature extractor commun
  feature_extractor:
    layers:
      - size: 512
        batch_norm: true
        dropout: 0.2
      - size: 256
        batch_norm: true
        dropout: 0.15
      - size: 128
        batch_norm: true
        dropout: 0.1
  
  # Tête L_ecran (signal fort)
  L_ecran_head:
    layers:
      - size: 64
        dropout: 0.05
      - size: 32
        dropout: 0.0
      - size: 1
  
  # Tête gap avec attention (signal faible)
  gap_head:
    attention_mechanism: true
    attention_size: 128
    layers:
      - size: 96
        dropout: 0.1
      - size: 64
        dropout: 0.05
      - size: 32
        dropout: 0.0
      - size: 1

training:
  # Paramètres optimisés pour les 5 problèmes identifiés
  batch_size: 32
  epochs: 200
  learning_rate: 0.001
  optimizer: "AdamW"
  weight_decay: 0.0001
  
  # Loss pondérée pour gap
  loss_function: "WeightedMSE"
  gap_weight: 30.0  # Poids élevé pour le gap
  L_ecran_weight: 1.0
  
  # Early stopping et scheduler
  early_stopping:
    patience: 25
    min_delta: 0.0001
    restore_best_weights: true
  
  lr_scheduler:
    type: "ReduceLROnPlateau"
    factor: 0.5
    patience: 10
    min_lr: 0.00001

data_preprocessing:
  # Solutions aux 5 problèmes identifiés
  label_rounding:
    enable: true
    decimals: 3  # Arrondissement à 3 décimales
  
  experimental_focus:
    enable: true
    gap_range: [0.025, 0.517]  # Focus sur plage expérimentale
  
  separate_normalization:
    enable: true
    L_ecran_scaler: "StandardScaler"
    gap_scaler: "StandardScaler"
    profiles_scaler: "StandardScaler"
  
  profile_truncation:
    enable: true
    truncate_to: 600  # Éviter divergence à haute distance

data_splits:
  train: 0.8
  validation: 0.2
  stratification: false  # Pas de stratification pour régression

evaluation:
  # Évaluation avec tolérance adaptative
  tolerance_evaluation:
    enable: true
    tolerance_L: 0.5  # µm pour L_ecran
    tolerance_gap: 0.01  # µm pour gap (2 décimales)
  
  performance_targets:
    r2_L_ecran: 0.95
    r2_gap: 0.8  # Plus difficile pour gap
    tolerance_accuracy_gap: 0.9  # 90% dans tolérance

monitoring:
  log_frequency: 10  # Log toutes les 10 epochs
  save_best_model: true
  track_metrics:
    - "train_loss"
    - "val_loss"
    - "train_r2_L"
    - "train_r2_gap"
    - "val_r2_L"
    - "val_r2_gap"
    - "tolerance_accuracy"

paths:
  data_file: "../data_generation/all_banque_new_24_01_25_NEW_full.mat"
  models_dir: "models/"
  plots_dir: "plots/"
  results_dir: "results/"
  processed_data_dir: "processed_data/"

visualization:
  generate_plots: true
  plot_types:
    - "training_curves"
    - "predictions_scatter"
    - "tolerance_analysis"
    - "attention_weights"
    - "residuals_analysis"
    - "parameter_correlation"

problem_solving:
  # Solutions aux 5 problèmes identifiés
  problems_addressed:
    1: "Précision excessive des labels → Arrondissement à 3 décimales"
    2: "Échelles déséquilibrées → Normalisation séparée par paramètre"
    3: "Distribution déséquilibrée → Focus sur plage expérimentale"
    4: "Loss function inadaptée → Loss pondérée pour gap"
    5: "Signal gap faible → Architecture spécialisée avec attention"

advanced_features:
  # Fonctionnalités avancées
  attention_mechanism:
    enable: true
    type: "self_attention"
    heads: 1
    dropout: 0.1
  
  ensemble_training:
    enable: false  # Désactivé par défaut
    n_models: 3
    gap_weights: [30, 50, 70]
  
  gradient_clipping:
    enable: true
    max_norm: 1.0
  
  weight_initialization:
    type: "kaiming_normal"
    nonlinearity: "relu"

expected_results:
  # Résultats attendus après résolution des problèmes
  L_ecran_prediction:
    r2_score: "> 0.95"
    rmse: "< 0.1 µm"
    tolerance_accuracy: "> 95%"
  
  gap_prediction:
    r2_score: "> 0.8"
    rmse: "< 0.05 µm"
    tolerance_accuracy: "> 90%"
  
  overall_performance:
    convergence: "< 100 epochs"
    training_stability: "stable"
    generalization: "good"

# Configuration for PyTorch Optimized Network
# Author: Oussama GUELFAA
# Date: 10 - 01 - 2025

experiment:
  name: "PyTorch_Optimized_Network"
  description: "Réseau PyTorch optimisé avec ResNet 1D et techniques avancées"
  version: "optimized"

model:
  name: "OptimizedPyTorchRegressor"
  type: "ResNet_1D_Optimized"
  input_size: 1000  # Profils complets
  output_size: 2    # L_ecran et gap
  
architecture:
  # ResNet 1D avec blocs résiduels
  backbone: "ResNet1D"
  
  conv_blocks:
    - channels: 64
      kernel_size: 7
      stride: 2
      padding: 3
    - channels: 128
      kernel_size: 5
      stride: 2
      padding: 2
    - channels: 256
      kernel_size: 3
      stride: 2
      padding: 1
    - channels: 512
      kernel_size: 3
      stride: 2
      padding: 1
  
  residual_blocks:
    - input_channels: 128
      output_channels: 128
      num_blocks: 2
    - input_channels: 256
      output_channels: 256
      num_blocks: 2
  
  dense_layers:
    - size: 256
      dropout: 0.3
    - size: 128
      dropout: 0.2
    - size: 2

training:
  # Optimisations PyTorch avancées
  batch_size: 32
  epochs: 200
  learning_rate: 0.001
  optimizer: "Adam"
  weight_decay: 0.0001
  
  # Loss function
  loss_function: "MSE"
  
  # Scheduler avancé
  lr_scheduler:
    type: "CosineAnnealingWarmRestarts"
    T_0: 10
    T_mult: 2
    eta_min: 0.00001
  
  # Early stopping
  early_stopping:
    patience: 20
    min_delta: 0.0001
    restore_best_weights: true
  
  # Optimisations avancées
  mixed_precision: false  # AMP pour GPU
  gradient_accumulation: 1
  gradient_clipping:
    enable: true
    max_norm: 1.0

data:
  # Données complètes sans troncature
  use_full_profiles: true
  profile_length: 1000
  
  # Augmentation de données
  data_augmentation:
    enable: true
    noise_level: 0.01
    rotation: false
    scaling: false
  
  # Normalisation
  normalization: "StandardScaler"
  
  # Splits
  train_split: 0.8
  val_split: 0.2

evaluation:
  metrics:
    - "r2_score"
    - "mse"
    - "mae"
    - "rmse"
  
  performance_targets:
    r2_L_ecran: 0.95
    r2_gap: 0.8
    r2_global: 0.85

advanced_features:
  # Techniques PyTorch avancées
  weight_initialization:
    type: "kaiming_normal"
    mode: "fan_out"
    nonlinearity: "relu"
  
  batch_normalization: true
  dropout_schedule: "fixed"  # ou "adaptive"
  
  # Monitoring avancé
  tensorboard_logging: false
  model_checkpointing: true
  
  # Optimisations mémoire
  memory_efficient: true
  pin_memory: true
  num_workers: 4

paths:
  data_file: "../data_generation/all_banque_new_24_01_25_NEW_full.mat"
  models_dir: "models/"
  plots_dir: "plots/"
  results_dir: "results/"
  logs_dir: "logs/"

visualization:
  generate_plots: true
  plot_types:
    - "training_curves"
    - "architecture_diagram"
    - "feature_maps"
    - "predictions_analysis"
    - "residual_analysis"

expected_results:
  # Résultats PyTorch optimisés
  performance:
    r2_global: "> 0.95"
    convergence: "< 100 epochs"
    training_time: "< 10 minutes"
    memory_usage: "optimized"
  
  advantages:
    - "Architecture ResNet 1D robuste"
    - "Scheduler adaptatif avancé"
    - "Optimisations mémoire"
    - "Monitoring complet"
